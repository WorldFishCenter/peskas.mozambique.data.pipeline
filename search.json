[{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU General Public License","title":"GNU General Public License","text":"Version 3, 29 June 2007Copyright © 2007 Free Software Foundation, Inc. <http://fsf.org/> Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU General Public License","text":"GNU General Public License free, copyleft license software kinds works. licenses software practical works designed take away freedom share change works. contrast, GNU General Public License intended guarantee freedom share change versions program–make sure remains free software users. , Free Software Foundation, use GNU General Public License software; applies also work released way authors. can apply programs, . speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge wish), receive source code can get want , can change software use pieces new free programs, know can things. protect rights, need prevent others denying rights asking surrender rights. Therefore, certain responsibilities distribute copies software, modify : responsibilities respect freedom others. example, distribute copies program, whether gratis fee, must pass recipients freedoms received. must make sure , , receive can get source code. must show terms know rights. Developers use GNU GPL protect rights two steps: (1) assert copyright software, (2) offer License giving legal permission copy, distribute /modify . developers’ authors’ protection, GPL clearly explains warranty free software. users’ authors’ sake, GPL requires modified versions marked changed, problems attributed erroneously authors previous versions. devices designed deny users access install run modified versions software inside , although manufacturer can . fundamentally incompatible aim protecting users’ freedom change software. systematic pattern abuse occurs area products individuals use, precisely unacceptable. Therefore, designed version GPL prohibit practice products. problems arise substantially domains, stand ready extend provision domains future versions GPL, needed protect freedom users. Finally, every program threatened constantly software patents. States allow patents restrict development use software general-purpose computers, , wish avoid special danger patents applied free program make effectively proprietary. prevent , GPL assures patents used render program non-free. precise terms conditions copying, distribution modification follow.","code":""},{"path":[]},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/LICENSE.html","id":"id_0-definitions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"0. Definitions","title":"GNU General Public License","text":"“License” refers version 3 GNU General Public License. “Copyright” also means copyright-like laws apply kinds works, semiconductor masks. “Program” refers copyrightable work licensed License. licensee addressed “”. “Licensees” “recipients” may individuals organizations. “modify” work means copy adapt part work fashion requiring copyright permission, making exact copy. resulting work called “modified version” earlier work work “based ” earlier work. “covered work” means either unmodified Program work based Program. “propagate” work means anything , without permission, make directly secondarily liable infringement applicable copyright law, except executing computer modifying private copy. Propagation includes copying, distribution (without modification), making available public, countries activities well. “convey” work means kind propagation enables parties make receive copies. Mere interaction user computer network, transfer copy, conveying. interactive user interface displays “Appropriate Legal Notices” extent includes convenient prominently visible feature (1) displays appropriate copyright notice, (2) tells user warranty work (except extent warranties provided), licensees may convey work License, view copy License. interface presents list user commands options, menu, prominent item list meets criterion.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/LICENSE.html","id":"id_1-source-code","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"1. Source Code","title":"GNU General Public License","text":"“source code” work means preferred form work making modifications . “Object code” means non-source form work. “Standard Interface” means interface either official standard defined recognized standards body, , case interfaces specified particular programming language, one widely used among developers working language. “System Libraries” executable work include anything, work whole, () included normal form packaging Major Component, part Major Component, (b) serves enable use work Major Component, implement Standard Interface implementation available public source code form. “Major Component”, context, means major essential component (kernel, window system, ) specific operating system () executable work runs, compiler used produce work, object code interpreter used run . “Corresponding Source” work object code form means source code needed generate, install, (executable work) run object code modify work, including scripts control activities. However, include work’s System Libraries, general-purpose tools generally available free programs used unmodified performing activities part work. example, Corresponding Source includes interface definition files associated source files work, source code shared libraries dynamically linked subprograms work specifically designed require, intimate data communication control flow subprograms parts work. Corresponding Source need include anything users can regenerate automatically parts Corresponding Source. Corresponding Source work source code form work.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/LICENSE.html","id":"id_2-basic-permissions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"2. Basic Permissions","title":"GNU General Public License","text":"rights granted License granted term copyright Program, irrevocable provided stated conditions met. License explicitly affirms unlimited permission run unmodified Program. output running covered work covered License output, given content, constitutes covered work. License acknowledges rights fair use equivalent, provided copyright law. may make, run propagate covered works convey, without conditions long license otherwise remains force. may convey covered works others sole purpose make modifications exclusively , provide facilities running works, provided comply terms License conveying material control copyright. thus making running covered works must exclusively behalf, direction control, terms prohibit making copies copyrighted material outside relationship . Conveying circumstances permitted solely conditions stated . Sublicensing allowed; section 10 makes unnecessary.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/LICENSE.html","id":"id_3-protecting-users-legal-rights-from-anti-circumvention-law","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"3. Protecting Users’ Legal Rights From Anti-Circumvention Law","title":"GNU General Public License","text":"covered work shall deemed part effective technological measure applicable law fulfilling obligations article 11 WIPO copyright treaty adopted 20 December 1996, similar laws prohibiting restricting circumvention measures. convey covered work, waive legal power forbid circumvention technological measures extent circumvention effected exercising rights License respect covered work, disclaim intention limit operation modification work means enforcing, work’s users, third parties’ legal rights forbid circumvention technological measures.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/LICENSE.html","id":"id_4-conveying-verbatim-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"4. Conveying Verbatim Copies","title":"GNU General Public License","text":"may convey verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice; keep intact notices stating License non-permissive terms added accord section 7 apply code; keep intact notices absence warranty; give recipients copy License along Program. may charge price price copy convey, may offer support warranty protection fee.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/LICENSE.html","id":"id_5-conveying-modified-source-versions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"5. Conveying Modified Source Versions","title":"GNU General Public License","text":"may convey work based Program, modifications produce Program, form source code terms section 4, provided also meet conditions: ) work must carry prominent notices stating modified , giving relevant date. b) work must carry prominent notices stating released License conditions added section 7. requirement modifies requirement section 4 “keep intact notices”. c) must license entire work, whole, License anyone comes possession copy. License therefore apply, along applicable section 7 additional terms, whole work, parts, regardless packaged. License gives permission license work way, invalidate permission separately received . d) work interactive user interfaces, must display Appropriate Legal Notices; however, Program interactive interfaces display Appropriate Legal Notices, work need make . compilation covered work separate independent works, nature extensions covered work, combined form larger program, volume storage distribution medium, called “aggregate” compilation resulting copyright used limit access legal rights compilation’s users beyond individual works permit. Inclusion covered work aggregate cause License apply parts aggregate.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/LICENSE.html","id":"id_6-conveying-non-source-forms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"6. Conveying Non-Source Forms","title":"GNU General Public License","text":"may convey covered work object code form terms sections 4 5, provided also convey machine-readable Corresponding Source terms License, one ways: ) Convey object code , embodied , physical product (including physical distribution medium), accompanied Corresponding Source fixed durable physical medium customarily used software interchange. b) Convey object code , embodied , physical product (including physical distribution medium), accompanied written offer, valid least three years valid long offer spare parts customer support product model, give anyone possesses object code either (1) copy Corresponding Source software product covered License, durable physical medium customarily used software interchange, price reasonable cost physically performing conveying source, (2) access copy Corresponding Source network server charge. c) Convey individual copies object code copy written offer provide Corresponding Source. alternative allowed occasionally noncommercially, received object code offer, accord subsection 6b. d) Convey object code offering access designated place (gratis charge), offer equivalent access Corresponding Source way place charge. need require recipients copy Corresponding Source along object code. place copy object code network server, Corresponding Source may different server (operated third party) supports equivalent copying facilities, provided maintain clear directions next object code saying find Corresponding Source. Regardless server hosts Corresponding Source, remain obligated ensure available long needed satisfy requirements. e) Convey object code using peer--peer transmission, provided inform peers object code Corresponding Source work offered general public charge subsection 6d. separable portion object code, whose source code excluded Corresponding Source System Library, need included conveying object code work. “User Product” either (1) “consumer product”, means tangible personal property normally used personal, family, household purposes, (2) anything designed sold incorporation dwelling. determining whether product consumer product, doubtful cases shall resolved favor coverage. particular product received particular user, “normally used” refers typical common use class product, regardless status particular user way particular user actually uses, expects expected use, product. product consumer product regardless whether product substantial commercial, industrial non-consumer uses, unless uses represent significant mode use product. “Installation Information” User Product means methods, procedures, authorization keys, information required install execute modified versions covered work User Product modified version Corresponding Source. information must suffice ensure continued functioning modified object code case prevented interfered solely modification made. convey object code work section , , specifically use , User Product, conveying occurs part transaction right possession use User Product transferred recipient perpetuity fixed term (regardless transaction characterized), Corresponding Source conveyed section must accompanied Installation Information. requirement apply neither third party retains ability install modified object code User Product (example, work installed ROM). requirement provide Installation Information include requirement continue provide support service, warranty, updates work modified installed recipient, User Product modified installed. Access network may denied modification materially adversely affects operation network violates rules protocols communication across network. Corresponding Source conveyed, Installation Information provided, accord section must format publicly documented (implementation available public source code form), must require special password key unpacking, reading copying.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/LICENSE.html","id":"id_7-additional-terms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"7. Additional Terms","title":"GNU General Public License","text":"“Additional permissions” terms supplement terms License making exceptions one conditions. Additional permissions applicable entire Program shall treated though included License, extent valid applicable law. additional permissions apply part Program, part may used separately permissions, entire Program remains governed License without regard additional permissions. convey copy covered work, may option remove additional permissions copy, part . (Additional permissions may written require removal certain cases modify work.) may place additional permissions material, added covered work, can give appropriate copyright permission. Notwithstanding provision License, material add covered work, may (authorized copyright holders material) supplement terms License terms: ) Disclaiming warranty limiting liability differently terms sections 15 16 License; b) Requiring preservation specified reasonable legal notices author attributions material Appropriate Legal Notices displayed works containing ; c) Prohibiting misrepresentation origin material, requiring modified versions material marked reasonable ways different original version; d) Limiting use publicity purposes names licensors authors material; e) Declining grant rights trademark law use trade names, trademarks, service marks; f) Requiring indemnification licensors authors material anyone conveys material (modified versions ) contractual assumptions liability recipient, liability contractual assumptions directly impose licensors authors. non-permissive additional terms considered “restrictions” within meaning section 10. Program received , part , contains notice stating governed License along term restriction, may remove term. license document contains restriction permits relicensing conveying License, may add covered work material governed terms license document, provided restriction survive relicensing conveying. add terms covered work accord section, must place, relevant source files, statement additional terms apply files, notice indicating find applicable terms. Additional terms, permissive non-permissive, may stated form separately written license, stated exceptions; requirements apply either way.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/LICENSE.html","id":"id_8-termination","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"8. Termination","title":"GNU General Public License","text":"may propagate modify covered work except expressly provided License. attempt otherwise propagate modify void, automatically terminate rights License (including patent licenses granted third paragraph section 11). However, cease violation License, license particular copyright holder reinstated () provisionally, unless copyright holder explicitly finally terminates license, (b) permanently, copyright holder fails notify violation reasonable means prior 60 days cessation. Moreover, license particular copyright holder reinstated permanently copyright holder notifies violation reasonable means, first time received notice violation License (work) copyright holder, cure violation prior 30 days receipt notice. Termination rights section terminate licenses parties received copies rights License. rights terminated permanently reinstated, qualify receive new licenses material section 10.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/LICENSE.html","id":"id_9-acceptance-not-required-for-having-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"9. Acceptance Not Required for Having Copies","title":"GNU General Public License","text":"required accept License order receive run copy Program. Ancillary propagation covered work occurring solely consequence using peer--peer transmission receive copy likewise require acceptance. However, nothing License grants permission propagate modify covered work. actions infringe copyright accept License. Therefore, modifying propagating covered work, indicate acceptance License .","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/LICENSE.html","id":"id_10-automatic-licensing-of-downstream-recipients","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"10. Automatic Licensing of Downstream Recipients","title":"GNU General Public License","text":"time convey covered work, recipient automatically receives license original licensors, run, modify propagate work, subject License. responsible enforcing compliance third parties License. “entity transaction” transaction transferring control organization, substantially assets one, subdividing organization, merging organizations. propagation covered work results entity transaction, party transaction receives copy work also receives whatever licenses work party’s predecessor interest give previous paragraph, plus right possession Corresponding Source work predecessor interest, predecessor can get reasonable efforts. may impose restrictions exercise rights granted affirmed License. example, may impose license fee, royalty, charge exercise rights granted License, may initiate litigation (including cross-claim counterclaim lawsuit) alleging patent claim infringed making, using, selling, offering sale, importing Program portion .","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/LICENSE.html","id":"id_11-patents","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"11. Patents","title":"GNU General Public License","text":"“contributor” copyright holder authorizes use License Program work Program based. work thus licensed called contributor’s “contributor version”. contributor’s “essential patent claims” patent claims owned controlled contributor, whether already acquired hereafter acquired, infringed manner, permitted License, making, using, selling contributor version, include claims infringed consequence modification contributor version. purposes definition, “control” includes right grant patent sublicenses manner consistent requirements License. contributor grants non-exclusive, worldwide, royalty-free patent license contributor’s essential patent claims, make, use, sell, offer sale, import otherwise run, modify propagate contents contributor version. following three paragraphs, “patent license” express agreement commitment, however denominated, enforce patent (express permission practice patent covenant sue patent infringement). “grant” patent license party means make agreement commitment enforce patent party. convey covered work, knowingly relying patent license, Corresponding Source work available anyone copy, free charge terms License, publicly available network server readily accessible means, must either (1) cause Corresponding Source available, (2) arrange deprive benefit patent license particular work, (3) arrange, manner consistent requirements License, extend patent license downstream recipients. “Knowingly relying” means actual knowledge , patent license, conveying covered work country, recipient’s use covered work country, infringe one identifiable patents country reason believe valid. , pursuant connection single transaction arrangement, convey, propagate procuring conveyance , covered work, grant patent license parties receiving covered work authorizing use, propagate, modify convey specific copy covered work, patent license grant automatically extended recipients covered work works based . patent license “discriminatory” include within scope coverage, prohibits exercise , conditioned non-exercise one rights specifically granted License. may convey covered work party arrangement third party business distributing software, make payment third party based extent activity conveying work, third party grants, parties receive covered work , discriminatory patent license () connection copies covered work conveyed (copies made copies), (b) primarily connection specific products compilations contain covered work, unless entered arrangement, patent license granted, prior 28 March 2007. Nothing License shall construed excluding limiting implied license defenses infringement may otherwise available applicable patent law.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/LICENSE.html","id":"id_12-no-surrender-of-others-freedom","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"12. No Surrender of Others’ Freedom","title":"GNU General Public License","text":"conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. convey covered work satisfy simultaneously obligations License pertinent obligations, consequence may convey . example, agree terms obligate collect royalty conveying convey Program, way satisfy terms License refrain entirely conveying Program.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/LICENSE.html","id":"id_13-use-with-the-gnu-affero-general-public-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"13. Use with the GNU Affero General Public License","title":"GNU General Public License","text":"Notwithstanding provision License, permission link combine covered work work licensed version 3 GNU Affero General Public License single combined work, convey resulting work. terms License continue apply part covered work, special requirements GNU Affero General Public License, section 13, concerning interaction network apply combination .","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/LICENSE.html","id":"id_14-revised-versions-of-this-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"14. Revised Versions of this License","title":"GNU General Public License","text":"Free Software Foundation may publish revised /new versions GNU General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies certain numbered version GNU General Public License “later version” applies , option following terms conditions either numbered version later version published Free Software Foundation. Program specify version number GNU General Public License, may choose version ever published Free Software Foundation. Program specifies proxy can decide future versions GNU General Public License can used, proxy’s public statement acceptance version permanently authorizes choose version Program. Later license versions may give additional different permissions. However, additional obligations imposed author copyright holder result choosing follow later version.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/LICENSE.html","id":"id_15-disclaimer-of-warranty","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"15. Disclaimer of Warranty","title":"GNU General Public License","text":"WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM “” WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/LICENSE.html","id":"id_16-limitation-of-liability","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"16. Limitation of Liability","title":"GNU General Public License","text":"EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MODIFIES /CONVEYS PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/LICENSE.html","id":"id_17-interpretation-of-sections-15-and-16","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"17. Interpretation of Sections 15 and 16","title":"GNU General Public License","text":"disclaimer warranty limitation liability provided given local legal effect according terms, reviewing courts shall apply local law closely approximates absolute waiver civil liability connection Program, unless warranty assumption liability accompanies copy Program return fee. END TERMS CONDITIONS","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/LICENSE.html","id":"how-to-apply-these-terms-to-your-new-programs","dir":"","previous_headings":"","what":"How to Apply These Terms to Your New Programs","title":"GNU General Public License","text":"develop new program, want greatest possible use public, best way achieve make free software everyone can redistribute change terms. , attach following notices program. safest attach start source file effectively state exclusion warranty; file least “copyright” line pointer full notice found. Also add information contact electronic paper mail. program terminal interaction, make output short notice like starts interactive mode: hypothetical commands show w show c show appropriate parts General Public License. course, program’s commands might different; GUI interface, use “box”. also get employer (work programmer) school, , sign “copyright disclaimer” program, necessary. information , apply follow GNU GPL, see <http://www.gnu.org/licenses/>. GNU General Public License permit incorporating program proprietary programs. program subroutine library, may consider useful permit linking proprietary applications library. want , use GNU Lesser General Public License instead License. first, please read <http://www.gnu.org/philosophy/--lgpl.html>.","code":"<one line to give the program's name and a brief idea of what it does.> Copyright (C) <year>  <name of author>  This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.  This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.  You should have received a copy of the GNU General Public License along with this program.  If not, see <http://www.gnu.org/licenses/>. <program>  Copyright (C) <year>  <name of author> This program comes with ABSOLUTELY NO WARRANTY; for details type 'show w'. This is free software, and you are welcome to redistribute it under certain conditions; type 'show c' for details."},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"First Last. Author, maintainer.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Last F (2025). peskas.mozambique.data.pipeline: Package (One Line, Title Case). R package version 2.1.0, https://worldfishcenter.github.io/peskas.mozambique.data.pipeline/.","code":"@Manual{,   title = {peskas.mozambique.data.pipeline: What the Package Does (One Line, Title Case)},   author = {First Last},   year = {2025},   note = {R package version 2.1.0},   url = {https://worldfishcenter.github.io/peskas.mozambique.data.pipeline/}, }"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/index.html","id":"peskasmozambiquedatapipeline","dir":"","previous_headings":"","what":"What the Package Does (One Line, Title Case)","title":"What the Package Does (One Line, Title Case)","text":"goal peskas.mozambique.data.pipeline implement, deploy, execute data modelling pipelines underpin Peskas Mozambique. ## pipeline R package peskas.mozambique.data.pipeline structured R package makes easier write production-grade software. Specifically, structuring code R package allows us : better handle system package dependencies, forces us split code functions, makes easier document code, makes easier test code make heavy use tidyverse style conventions usethis package automate tasks project setup deployment. information rationale structuring pipeline package check Chapter 3 Engineering Production-Grade Shiny Apps. book focused Shiny applications rationale also applies data pipelines production-ready code general.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/index.html","id":"how-the-pipeline-works","dir":"","previous_headings":"","what":"How the pipeline works","title":"What the Package Does (One Line, Title Case)","text":"pipeline composed different modules: Data Collection: site fishing landing surveys continuous, solar-powered GPS vessel trackers collect send data near real-time, alongside fishery metadata thorough data-gathering process. Pre-processing: Data formatting, shaping, standardisation prepare raw data analysis. Validation: Outlier detection error identification, includes alert system maintain data quality. Analytics: Modelling fisheries indicators, nutritional characterization, data mining extract valuable insights. Data export: Automated dissemination processed analysed fisheries data ensure accessibility comprehension. involves restructuring data dashboard integration open publication. isualisation: Tools data reporting sharing insights comprehensive dedicated web app dashboard (hosted repository). See Peskas: Automated analytics small-scale, data-deficient fisheries details.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/index.html","id":"getting-started","dir":"","previous_headings":"","what":"Getting Started","title":"What the Package Does (One Line, Title Case)","text":"package uses configuration file config.yml manage environment-specific settings connections. get started, familiarize package structure, particularly R directory main functions located. function typically reads configuration using read_config() access necessary parameters. work package locally, ’ll need copy .env.example .env fill authentication credentials. read_config() function automatically loads environment variables .env file. Remember run devtools::load_all() testing changes locally. ’re new R package development, consider reviewing R packages book Hadley Wickham Jenny Brian.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/index.html","id":"quick-guide-for-contributors","dir":"","previous_headings":"","what":"Quick Guide for Contributors","title":"What the Package Does (One Line, Title Case)","text":"keep repository clean efficient, please keep guidelines mind: Always work new branch, directly main. Write clear, concise commit messages. Avoid storing intermediate garbage files, especially root folder. Strive soft-coded solutions. Maintain consistent code style throughout project. Document code well - future (others) thank . Test changes thoroughly submitting pull request. Keep fork synced main repository. practices help us maintain clean, efficient codebase ’s easier everyone work . detailed guidelines, check CONTRIBUTING.md file.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/add_version.html","id":null,"dir":"Reference","previous_headings":"","what":"Add timestamp and sha string to a file name — add_version","title":"Add timestamp and sha string to a file name — add_version","text":"alternative version data name using sha (unique identifier) code using generate process data time data generated processed. function adds information, version identifier, file name (character string)","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/add_version.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add timestamp and sha string to a file name — add_version","text":"","code":"add_version(filename, extension = \"\", sha_nchar = 7, sep = \"__\")"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/add_version.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add timestamp and sha string to a file name — add_version","text":"filename Path sans extension file version extension Extension file sha_nchar Number characters SHA use version identifier sep Characters separating version identifier file name","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/add_version.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add timestamp and sha string to a file name — add_version","text":"character string file name version identifier","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/add_version.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Add timestamp and sha string to a file name — add_version","text":"SHA information retrieved using git2r::sha. code running context aware git repository (example code running inside container) function attempts get sha environment variable GITHUB_SHA. methods fail, sha versioning added.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/add_version.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add timestamp and sha string to a file name — add_version","text":"","code":"if (git2r::in_repository()) {   add_version(\"my_file\", \"csv\") } #> [1] \"my_file__20251110161616_4a0b5ce__.csv\""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/airtable_to_df.html","id":null,"dir":"Reference","previous_headings":"","what":"Get All Records from Airtable with Pagination — airtable_to_df","title":"Get All Records from Airtable with Pagination — airtable_to_df","text":"Retrieves records Airtable table, handling pagination automatically.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/airtable_to_df.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get All Records from Airtable with Pagination — airtable_to_df","text":"","code":"airtable_to_df(base_id, table_name, token, list_handler = \"collapse\")"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/airtable_to_df.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get All Records from Airtable with Pagination — airtable_to_df","text":"base_id Character string. Airtable base ID. table_name Character string. name table retrieve. token Character string. Airtable API token authentication. list_handler Character string. \"collapse\" (default) \"count\" list fields.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/airtable_to_df.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get All Records from Airtable with Pagination — airtable_to_df","text":"tibble records 'airtable_id' column.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/alert_outlier.html","id":null,"dir":"Reference","previous_headings":"","what":"Outlier Alert for Numeric Vectors — alert_outlier","title":"Outlier Alert for Numeric Vectors — alert_outlier","text":"helper function identifies numeric outliers based bounds computed LocScaleB. optionally applies log transform within LocScaleB (... argument) flags values outside computed lower upper bounds. Values lower bound receive alert code alert_if_smaller, values upper bound receive alert_if_larger, -range values receive no_alert_value.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/alert_outlier.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Outlier Alert for Numeric Vectors — alert_outlier","text":"","code":"alert_outlier(   x,   no_alert_value = NA_real_,   alert_if_larger = no_alert_value,   alert_if_smaller = no_alert_value,   ... )"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/alert_outlier.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Outlier Alert for Numeric Vectors — alert_outlier","text":"x numeric vector detect outliers. no_alert_value numeric code (default NA_real_) assign non-outlier values. alert_if_larger numeric code assign x > upper bound. alert_if_smaller numeric code assign x < lower bound. ... Additional arguments passed LocScaleB, logt k.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/alert_outlier.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Outlier Alert for Numeric Vectors — alert_outlier","text":"numeric vector length x, containing alert codes element (alert_if_smaller, alert_if_larger, no_alert_value).","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/alert_outlier.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Outlier Alert for Numeric Vectors — alert_outlier","text":"function checks x values NA zero, MAD (median absolute deviation) zero. cases, returns NA elements, since meaningful bounds computed. Otherwise, calls univOutl::LocScaleB(x, ...) compute bounds. log transform used (logt = TRUE), LocScaleB returns log-scale bounds; typically, back-transform compare raw values.","code":""},{"path":[]},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/alert_outlier.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Outlier Alert for Numeric Vectors — alert_outlier","text":"","code":"if (FALSE) { # \\dontrun{ x <- c(1, 2, 3, 100) alert_outlier(x, no_alert_value = NA, alert_if_larger = 9, logt = TRUE, k = 3) } # }"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/bulk_update_airtable.html","id":null,"dir":"Reference","previous_headings":"","what":"Bulk Update Multiple Airtable Records — bulk_update_airtable","title":"Bulk Update Multiple Airtable Records — bulk_update_airtable","text":"Updates multiple records batches 10.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/bulk_update_airtable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bulk Update Multiple Airtable Records — bulk_update_airtable","text":"","code":"bulk_update_airtable(base_id, table_name, token, updates_df)"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/bulk_update_airtable.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bulk Update Multiple Airtable Records — bulk_update_airtable","text":"base_id Character string. Airtable base ID. table_name Character string. Name table. token Character string. Airtable API token. updates_df Data frame 'airtable_id' column fields update.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/bulk_update_airtable.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bulk Update Multiple Airtable Records — bulk_update_airtable","text":"List response objects.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/calculate_catch_adnap.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Catch Weight from Length-Weight Relationships or Bucket Measurements — calculate_catch_adnap","title":"Calculate Catch Weight from Length-Weight Relationships or Bucket Measurements — calculate_catch_adnap","text":"Calculates total catch weight using either length-weight relationships bucket measurements. function prioritizes length-based calculations available, falling back bucket-based measurements length data missing. Octopus (OCZ), function converts total length (TL) mantle length (ML) dividing TL 5.5 applying length-weight formula. accounts species-specific differences body morphology.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/calculate_catch_adnap.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Catch Weight from Length-Weight Relationships or Bucket Measurements — calculate_catch_adnap","text":"","code":"calculate_catch_adnap(catch_data = NULL, lwcoeffs = NULL)"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/calculate_catch_adnap.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Catch Weight from Length-Weight Relationships or Bucket Measurements — calculate_catch_adnap","text":"catch_data data frame containing catch information columns: submission_id - Unique identifier catch n_catch - Number catch events catch_taxon - FAO 3-alpha code individuals - Number individuals (length-based calculations) length - Length measurement cm n_buckets - Number buckets weight_bucket - Weight per bucket kg lwcoeffs data frame containing length-weight coefficients columns: catch_taxon - FAO 3-alpha code a_6 - 60th percentile parameter '' b_6 - 60th percentile parameter 'b'","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/calculate_catch_adnap.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Catch Weight from Length-Weight Relationships or Bucket Measurements — calculate_catch_adnap","text":"tibble following columns: submission_id - Unique identifier catch n_catch - Number catch events catch_taxon - FAO 3-alpha code individuals - Number individuals length - Length measurement cm n_buckets - Number buckets weight_bucket - Weight per bucket kg catch_kg - Total catch weight kg","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/calculate_catch_adnap.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate Catch Weight from Length-Weight Relationships or Bucket Measurements — calculate_catch_adnap","text":"function calculates catch weight using two methods: Length-based calculation: W = * L^b * N / 1000 : W total weight kg b length-weight relationship coefficients (75th percentile) L length cm N number individuals Bucket-based calculation: W = n_buckets * weight_bucket : W total weight kg n_buckets number buckets weight_bucket weight per bucket kg final catch_kg uses length-based calculation available, falling back bucket-based calculation length data missing.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/calculate_catch_adnap.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Calculate Catch Weight from Length-Weight Relationships or Bucket Measurements — calculate_catch_adnap","text":"Length-based calculations use 75th percentile length-weight coefficients weights returned kilograms NA values returned neither calculation method possible","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/calculate_catch_adnap.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate Catch Weight from Length-Weight Relationships or Bucket Measurements — calculate_catch_adnap","text":"","code":"if (FALSE) { # \\dontrun{ # Calculate catch weights catch_weights <- calculate_catch_adnap(   catch_data = catch_data,   lwcoeffs = length_weight_coeffs ) } # }"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/calculate_catch_lurio.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Catch Weight from Length-Weight Relationships or Bucket Measurements — calculate_catch_lurio","title":"Calculate Catch Weight from Length-Weight Relationships or Bucket Measurements — calculate_catch_lurio","text":"Calculates total catch weight using either length-weight relationships bucket measurements. function prioritizes length-based calculations available, falling back bucket-based measurements length data missing. Octopus (OCZ), function converts total length (TL) mantle length (ML) dividing TL 5.5 applying length-weight formula. accounts species-specific differences body morphology.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/calculate_catch_lurio.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Catch Weight from Length-Weight Relationships or Bucket Measurements — calculate_catch_lurio","text":"","code":"calculate_catch_lurio(catch_data = NULL, lwcoeffs = NULL)"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/calculate_catch_lurio.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Catch Weight from Length-Weight Relationships or Bucket Measurements — calculate_catch_lurio","text":"catch_data data frame containing catch information columns: submission_id - Unique identifier catch n_catch - Number catch events catch_taxon - FAO 3-alpha code individuals - Number individuals (length-based calculations) length - Length measurement cm n_buckets - Number buckets weight_bucket - Weight per bucket kg lwcoeffs data frame containing length-weight coefficients columns: catch_taxon - FAO 3-alpha code a_6 - 60th percentile parameter '' b_6 - 60th percentile parameter 'b'","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/calculate_catch_lurio.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Catch Weight from Length-Weight Relationships or Bucket Measurements — calculate_catch_lurio","text":"tibble following columns: submission_id - Unique identifier catch n_catch - Number catch events catch_taxon - FAO 3-alpha code individuals - Number individuals length - Length measurement cm n_buckets - Number buckets weight_bucket - Weight per bucket kg catch_kg - Total catch weight kg","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/calculate_catch_lurio.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate Catch Weight from Length-Weight Relationships or Bucket Measurements — calculate_catch_lurio","text":"function calculates catch weight using two methods: Length-based calculation: W = * L^b * N / 1000 : W total weight kg b length-weight relationship coefficients (75th percentile) L length cm N number individuals Bucket-based calculation: W = n_buckets * weight_bucket : W total weight kg n_buckets number buckets weight_bucket weight per bucket kg final catch_kg uses length-based calculation available, falling back bucket-based calculation length data missing.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/calculate_catch_lurio.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Calculate Catch Weight from Length-Weight Relationships or Bucket Measurements — calculate_catch_lurio","text":"Length-based calculations use 75th percentile length-weight coefficients weights returned kilograms NA values returned neither calculation method possible","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/calculate_catch_lurio.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate Catch Weight from Length-Weight Relationships or Bucket Measurements — calculate_catch_lurio","text":"","code":"if (FALSE) { # \\dontrun{ # Calculate catch weights catch_weights <- calculate_catch_lurio(   catch_data = catch_data,   lwcoeffs = length_weight_coeffs ) } # }"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/calculate_fishery_metrics.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Fishery Metrics — calculate_fishery_metrics","title":"Calculate Fishery Metrics — calculate_fishery_metrics","text":"Transforms catch-level data normalized fishery performance indicators. Calculates site-level, gear-specific, species-specific metrics.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/calculate_fishery_metrics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Fishery Metrics — calculate_fishery_metrics","text":"","code":"calculate_fishery_metrics(data = NULL)"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/calculate_fishery_metrics.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Fishery Metrics — calculate_fishery_metrics","text":"data data frame catch records containing required columns: submission_id, landing_date, district, gear, catch_outcome, no_men_fishers, no_women_fishers, no_child_fishers, catch_taxon, catch_price, catch_kg","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/calculate_fishery_metrics.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Fishery Metrics — calculate_fishery_metrics","text":"data frame normalized long format columns: landing_site, year_month, metric_type, metric_value, gear_type, species, rank","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/cloud_object_name.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Cloud Object Name — cloud_object_name","title":"Generate Cloud Object Name — cloud_object_name","text":"function generates full object name file cloud storage, finding latest version specified.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/cloud_object_name.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate Cloud Object Name — cloud_object_name","text":"","code":"cloud_object_name(   prefix,   version = \"latest\",   extension = \"\",   provider,   exact_match = FALSE,   options )"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/cloud_object_name.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Cloud Object Name — cloud_object_name","text":"prefix character string specifying file prefix. version character string specifying version. Default \"latest\". extension character string specifying file extension. provider character string specifying cloud storage provider. exact_match logical value indicating whether match prefix exactly. options named list cloud storage provider options.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/cloud_object_name.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate Cloud Object Name — cloud_object_name","text":"character string full object name.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/cloud_storage_authenticate.html","id":null,"dir":"Reference","previous_headings":"","what":"Authenticate to a Cloud Storage Provider — cloud_storage_authenticate","title":"Authenticate to a Cloud Storage Provider — cloud_storage_authenticate","text":"function authenticates cloud storage provider using specified authentication method. Currently supports Google Cloud Storage (GCS) Amazon Web Services (AWS).","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/cloud_storage_authenticate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Authenticate to a Cloud Storage Provider — cloud_storage_authenticate","text":"","code":"cloud_storage_authenticate(provider, options)"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/cloud_storage_authenticate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Authenticate to a Cloud Storage Provider — cloud_storage_authenticate","text":"provider character string specifying cloud provider. Currently supports \"gcs\" Google Cloud Storage \"aws\" Amazon Web Services. options named list options specific cloud provider. GCS, include service_account_key contents authentication JSON file Google Project.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/cloud_storage_authenticate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Authenticate to a Cloud Storage Provider — cloud_storage_authenticate","text":"NULL (called side effects)","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/cloud_storage_authenticate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Authenticate to a Cloud Storage Provider — cloud_storage_authenticate","text":"","code":"if (FALSE) { # \\dontrun{ # Authenticate with Google Cloud Storage authentication_details <- readLines(\"path/to/json_file.json\") cloud_storage_authenticate(\"gcs\", list(service_account_key = authentication_details)) } # }"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/device_sync.html","id":null,"dir":"Reference","previous_headings":"","what":"Sync Data with Airtable (Update + Create) — device_sync","title":"Sync Data with Airtable (Update + Create) — device_sync","text":"Main function daily syncing. Updates existing records creates new ones.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/device_sync.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sync Data with Airtable (Update + Create) — device_sync","text":"","code":"device_sync(   boats_df,   base_id,   table_name = \"pds_devices\",   token,   key_field = \"imei\" )"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/device_sync.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sync Data with Airtable (Update + Create) — device_sync","text":"boats_df Data frame device data. Must include key_field column. base_id Character string. Airtable base ID. table_name Character string. Name table (default: \"pds_devices\"). token Character string. Airtable API token. key_field Character string. Field match (default: \"imei\").","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/device_sync.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sync Data with Airtable (Update + Create) — device_sync","text":"List update create results.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/df_to_airtable.html","id":null,"dir":"Reference","previous_headings":"","what":"Create New Airtable Records — df_to_airtable","title":"Create New Airtable Records — df_to_airtable","text":"Creates new records batches 10.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/df_to_airtable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create New Airtable Records — df_to_airtable","text":"","code":"df_to_airtable(df, base_id, table_name, token)"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/df_to_airtable.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create New Airtable Records — df_to_airtable","text":"df Data frame containing data create. base_id Character string. Airtable base ID. table_name Character string. Name table. token Character string. Airtable API token.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/df_to_airtable.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create New Airtable Records — df_to_airtable","text":"List response objects.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/download_cloud_file.html","id":null,"dir":"Reference","previous_headings":"","what":"Download File from Cloud Storage — download_cloud_file","title":"Download File from Cloud Storage — download_cloud_file","text":"function downloads one files cloud storage.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/download_cloud_file.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download File from Cloud Storage — download_cloud_file","text":"","code":"download_cloud_file(name, provider, options, file = name)"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/download_cloud_file.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download File from Cloud Storage — download_cloud_file","text":"name character vector object names cloud storage. provider character string specifying cloud storage provider. options named list cloud storage provider options. file character vector local file paths. Defaults object names.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/download_cloud_file.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download File from Cloud Storage — download_cloud_file","text":"character vector local file paths.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/download_cloud_file.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download File from Cloud Storage — download_cloud_file","text":"","code":"if (FALSE) { # \\dontrun{ download_cloud_file(   name = \"data/processed.parquet\",   provider = \"gcs\",   options = list(bucket = \"my-bucket\"),   file = \"local_data.parquet\" ) } # }"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/download_parquet_from_cloud.html","id":null,"dir":"Reference","previous_headings":"","what":"Download Parquet File from Cloud Storage — download_parquet_from_cloud","title":"Download Parquet File from Cloud Storage — download_parquet_from_cloud","text":"function downloads Parquet file cloud storage loads data frame.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/download_parquet_from_cloud.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download Parquet File from Cloud Storage — download_parquet_from_cloud","text":"","code":"download_parquet_from_cloud(prefix, provider, options)"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/download_parquet_from_cloud.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download Parquet File from Cloud Storage — download_parquet_from_cloud","text":"prefix character string specifying file prefix path cloud storage. provider character string specifying cloud storage provider key. options named list cloud storage provider options.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/download_parquet_from_cloud.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download Parquet File from Cloud Storage — download_parquet_from_cloud","text":"tibble containing data Parquet file.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/download_parquet_from_cloud.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download Parquet File from Cloud Storage — download_parquet_from_cloud","text":"","code":"if (FALSE) { # \\dontrun{ # Download survey data data <- download_parquet_from_cloud(   prefix = \"raw-data/survey-data\",   provider = conf$storage$google$key,   options = conf$storage$google$options ) } # }"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/export_landings.html","id":null,"dir":"Reference","previous_headings":"","what":"Export Processed Landings Data — export_landings","title":"Export Processed Landings Data — export_landings","text":"Exports validated landings data MongoDB collection. function filters transforms preprocessed data, calculates total catch weights, exports selected fields validated collection.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/export_landings.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Export Processed Landings Data — export_landings","text":"","code":"export_landings()"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/export_landings.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Export Processed Landings Data — export_landings","text":"None (invisible). Data exported directly MongoDB.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/export_landings.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Export Processed Landings Data — export_landings","text":"function performs following steps: Pulls preprocessed data MongoDB Calculates total catch weights per submission Filters valid survey activities (survey_activity == 1) Selects relevant fields export Uploads filtered data validated collection","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/export_landings.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Export Processed Landings Data — export_landings","text":"submissions survey_activity == 1 included export. Catch weights summed per submission, NA values removed.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/export_landings.html","id":"exported-fields","dir":"Reference","previous_headings":"","what":"Exported Fields","title":"Export Processed Landings Data — export_landings","text":"following fields included export: submission_id: Unique identifier submission landing_date: Date time landing district: Administrative district landing_site: Name landing site catch_outcome: Outcome catch lat: Latitude lon: Longitude habitat: Fishing habitat vessel_type: Type fishing vessel propulsion_gear: Type propulsion trip_duration: Duration fishing trip gear: Fishing gear used catch_df: Nested catch data","code":""},{"path":[]},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/export_landings.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Export Processed Landings Data — export_landings","text":"","code":"if (FALSE) { # \\dontrun{ export_landings() } # }"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/extract_trip_ids_from_filenames.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Trip IDs from Track Filenames — extract_trip_ids_from_filenames","title":"Extract Trip IDs from Track Filenames — extract_trip_ids_from_filenames","text":"Extract Trip IDs Track Filenames","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/extract_trip_ids_from_filenames.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Trip IDs from Track Filenames — extract_trip_ids_from_filenames","text":"","code":"extract_trip_ids_from_filenames(filenames)"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/extract_trip_ids_from_filenames.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Trip IDs from Track Filenames — extract_trip_ids_from_filenames","text":"filenames Character vector track filenames","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/extract_trip_ids_from_filenames.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Trip IDs from Track Filenames — extract_trip_ids_from_filenames","text":"Character vector trip IDs","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/fetch_asset.html","id":null,"dir":"Reference","previous_headings":"","what":"Fetch and Filter Asset Data from Airtable — fetch_asset","title":"Fetch and Filter Asset Data from Airtable — fetch_asset","text":"Retrieves data specified Airtable table filters based form ID. Handles cases form_id column contains multiple comma-separated IDs.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/fetch_asset.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fetch and Filter Asset Data from Airtable — fetch_asset","text":"","code":"fetch_asset(table_name = NULL, select_cols = NULL, form = NULL, conf = NULL)"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/fetch_asset.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fetch and Filter Asset Data from Airtable — fetch_asset","text":"table_name Character. Name Airtable table fetch. select_cols Character vector. Column names select table. form Character. Form ID filter . conf Configuration object read_config().","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/fetch_asset.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fetch and Filter Asset Data from Airtable — fetch_asset","text":"filtered selected data frame Airtable containing rows form_id field contains specified form ID.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/fetch_asset.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fetch and Filter Asset Data from Airtable — fetch_asset","text":"function uses string detection handle multi-valued form_id fields may contain comma-separated lists form IDs.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/fetch_assets.html","id":null,"dir":"Reference","previous_headings":"","what":"Fetch Multiple Asset Tables from Airtable — fetch_assets","title":"Fetch Multiple Asset Tables from Airtable — fetch_assets","text":"Fetches taxa, gear, vessels, landing sites data Airtable filtered specified form ID. Returns distinct records table.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/fetch_assets.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fetch Multiple Asset Tables from Airtable — fetch_assets","text":"","code":"fetch_assets(form_id = NULL, conf = NULL)"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/fetch_assets.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fetch Multiple Asset Tables from Airtable — fetch_assets","text":"form_id Character. Form ID filter assets . passed individual fetch_asset call. conf Configuration object read_config().","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/fetch_assets.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fetch Multiple Asset Tables from Airtable — fetch_assets","text":"named list containing four data frames: taxa: Contains survey_label, alpha3_code, scientific_name columns gear: Contains survey_label standard_name columns vessels: Contains survey_label standard_name columns sites: Contains site site_code columns","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/fetch_assets.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fetch Multiple Asset Tables from Airtable — fetch_assets","text":"table fetched separately using fetch_asset() filtered return distinct rows avoid duplicates mapping tables.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/flatten_field.html","id":null,"dir":"Reference","previous_headings":"","what":"Flatten Survey Data Fields — flatten_field","title":"Flatten Survey Data Fields — flatten_field","text":"Processes field within row survey data, handling simple vectors nested lists. lists named elements, renames unlists flat structure preparation.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/flatten_field.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Flatten Survey Data Fields — flatten_field","text":"","code":"flatten_field(x, p)"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/flatten_field.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Flatten Survey Data Fields — flatten_field","text":"x vector list representing field data. p prefix name associated field, used naming flattening process.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/flatten_field.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Flatten Survey Data Fields — flatten_field","text":"Modified field, either unchanged, unnested, appropriately renamed.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/flatten_row.html","id":null,"dir":"Reference","previous_headings":"","what":"Flatten Survey Data Rows — flatten_row","title":"Flatten Survey Data Rows — flatten_row","text":"Transforms row nested survey data flat tabular format using mapping flattening process.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/flatten_row.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Flatten Survey Data Rows — flatten_row","text":"","code":"flatten_row(x)"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/flatten_row.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Flatten Survey Data Rows — flatten_row","text":"x list representing row data, potentially containing nested lists vectors.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/flatten_row.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Flatten Survey Data Rows — flatten_row","text":"tibble row representing flattened survey data.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/generate_track_summaries.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate Grid Summaries for Track Data — generate_track_summaries","title":"Generate Grid Summaries for Track Data — generate_track_summaries","text":"Processes GPS track data 1km grid summaries visualization analysis.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/generate_track_summaries.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate Grid Summaries for Track Data — generate_track_summaries","text":"","code":"generate_track_summaries(data, min_hours = 0.15, max_hours = 15)"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/generate_track_summaries.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate Grid Summaries for Track Data — generate_track_summaries","text":"data Preprocessed track data min_hours Minimum hours threshold filtering (default: 0.15) max_hours Maximum hours threshold filtering (default: 10)","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/generate_track_summaries.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate Grid Summaries for Track Data — generate_track_summaries","text":"dataframe grid summary statistics","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/getLWCoeffs.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Length-Weight Coefficients and Morphological Data for Species — getLWCoeffs","title":"Get Length-Weight Coefficients and Morphological Data for Species — getLWCoeffs","text":"Retrieves summarizes length-weight relationship coefficients morphological data handling FishBase SeaLifeBase data single workflow.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/getLWCoeffs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Length-Weight Coefficients and Morphological Data for Species — getLWCoeffs","text":"","code":"getLWCoeffs(taxa_list = NULL, asfis_list = NULL)"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/getLWCoeffs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Length-Weight Coefficients and Morphological Data for Species — getLWCoeffs","text":"taxa_list Character vector FAO 3-alpha codes asfis_list ASFIS list data frame","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/getLWCoeffs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Length-Weight Coefficients and Morphological Data for Species — getLWCoeffs","text":"list two elements: lw - data frame length-weight coefficients: catch_taxon - FAO 3-alpha code n - Number measurements a_6 - 60th percentile parameter '' b_6 - 60th percentile parameter 'b' ml - data frame morphological data: catch_taxon - FAO 3-alpha code n - Number measurements max_length_75 - 75th percentile maximum length max_weightkg_75 - 75th percentile maximum weight kg","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/getLWCoeffs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Length-Weight Coefficients and Morphological Data for Species — getLWCoeffs","text":"","code":"if (FALSE) { # \\dontrun{ # Get coefficients and morphological data results <- getLWCoeffs(taxa_list, asfis_list)  # Access length-weight coefficients lw_coeffs <- results$lw  # Access morphological data morph_data <- results$ml } # }"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_airtable_form_id.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Airtable Form ID from KoBoToolbox Asset ID — get_airtable_form_id","title":"Get Airtable Form ID from KoBoToolbox Asset ID — get_airtable_form_id","text":"Retrieves Airtable record ID form based KoBoToolbox asset ID.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_airtable_form_id.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Airtable Form ID from KoBoToolbox Asset ID — get_airtable_form_id","text":"","code":"get_airtable_form_id(kobo_asset_id = NULL, conf = NULL)"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_airtable_form_id.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Airtable Form ID from KoBoToolbox Asset ID — get_airtable_form_id","text":"kobo_asset_id Character. KoBoToolbox asset ID match. conf Configuration object read_config().","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_airtable_form_id.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Airtable Form ID from KoBoToolbox Asset ID — get_airtable_form_id","text":"Character. Airtable record ID matching form.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_catch_bounds_taxon.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Catch Bounds by Gear + Taxon — get_catch_bounds_taxon","title":"Get Catch Bounds by Gear + Taxon — get_catch_bounds_taxon","text":"Computes upper/lower outlier bounds catch data (catch_kg) grouped interaction gear catch_taxon. function uses LocScaleB (default) log transform find outlier thresholds gear-taxont group, exponentiates upper bound.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_catch_bounds_taxon.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Catch Bounds by Gear + Taxon — get_catch_bounds_taxon","text":"","code":"get_catch_bounds_taxon(data, k)"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_catch_bounds_taxon.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Catch Bounds by Gear + Taxon — get_catch_bounds_taxon","text":"data data frame includes columns gear, catch_taxon, catch_kg. k numeric parameter passed LocScaleB, controlling \"wide\" outlier threshold (often k = 3 k = 2).","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_catch_bounds_taxon.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Catch Bounds by Gear + Taxon — get_catch_bounds_taxon","text":"data frame columns gear, catch_taxon, upper., bounds LocScaleB. lower.low column dropped.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_catch_bounds_taxon.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get Catch Bounds by Gear + Taxon — get_catch_bounds_taxon","text":"Filters columns gear, catch_taxon, catch_kg. Splits data interaction gear catch_taxon. Runs LocScaleB subset (logt = TRUE), retrieving bounds. Binds subset results, exponentiates upper.bound, separates gear_taxon back gear catch_taxon.","code":""},{"path":[]},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_catch_bounds_taxon.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Catch Bounds by Gear + Taxon — get_catch_bounds_taxon","text":"","code":"if (FALSE) { # \\dontrun{ data_bounds <- get_catch_bounds_taxon(data, k = 3) head(data_bounds) } # }"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_fao_groups.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract and Format FAO Taxonomic Groups — get_fao_groups","title":"Extract and Format FAO Taxonomic Groups — get_fao_groups","text":"Filters formats taxonomic information FAO ASFIS list specified FAO 3-alpha codes, excluding miscellaneous (\"MZZ\") unknown (\"UNKN\") categories.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_fao_groups.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract and Format FAO Taxonomic Groups — get_fao_groups","text":"","code":"get_fao_groups(fao_codes = NULL, asfis_list = NULL)"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_fao_groups.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract and Format FAO Taxonomic Groups — get_fao_groups","text":"fao_codes character vector FAO 3-alpha codes extract. NULL, returns empty dataset. asfis_list data frame containing FAO ASFIS list required columns: Alpha3_Code - FAO 3-alpha code Scientific_Name - Scientific name taxon English_name - Common name English Family - Family name Order - Order name ISSCAAP_Group - FAO ISSCAAP group number","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_fao_groups.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract and Format FAO Taxonomic Groups — get_fao_groups","text":"tibble standardized column names containing taxonomic information: a3_code - FAO 3-alpha code scientific_name - Scientific name english_name - Common name English family - Family name order - Order name taxon_group - ISSCAAP group number","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_fao_groups.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract and Format FAO Taxonomic Groups — get_fao_groups","text":"function: Filters ASFIS list specified FAO codes Standardizes column names consistency Removes miscellaneous (\"MZZ\") unknown (\"UNKN\") categories Preserves taxonomic hierarchy information","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_fao_groups.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Extract and Format FAO Taxonomic Groups — get_fao_groups","text":"Requires dplyr package MZZ (Miscellaneous marine fishes) UNKN (Unknown) automatically excluded Column names standardized consistency functions","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_fao_groups.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract and Format FAO Taxonomic Groups — get_fao_groups","text":"","code":"# Example ASFIS data asfis <- data.frame(   Alpha3_Code = c(\"TUN\", \"MZZ\", \"RAG\"),   Scientific_Name = c(\"Thunnini\", \"Marine fishes nei\", \"Rastrelliger kanagurta\"),   English_name = c(\"Tunas\", \"Marine fishes\", \"Indian mackerel\"),   Family = c(\"SCOMBRIDAE\", NA, \"SCOMBRIDAE\"),   Order = c(\"PERCIFORMES\", NA, \"PERCIFORMES\"),   ISSCAAP_Group = c(36, 39, 37) )  # Get taxonomic information for specific codes fao_taxa <- get_fao_groups(c(\"TUN\", \"RAG\"), asfis)"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_kobo_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve Data from Kobotoolbox API — get_kobo_data","title":"Retrieve Data from Kobotoolbox API — get_kobo_data","text":"function retrieves survey data Kobotoolbox API specific asset. supports pagination handles JSON XML formats.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_kobo_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve Data from Kobotoolbox API — get_kobo_data","text":"","code":"get_kobo_data(   assetid,   url = \"eu.kobotoolbox.org\",   uname = NULL,   pwd = NULL,   encoding = \"UTF-8\",   format = \"json\" )"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_kobo_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve Data from Kobotoolbox API — get_kobo_data","text":"assetid asset ID Kobotoolbox form. url URL Kobotoolbox (default \"eu.kobotoolbox.org\"). uname Username Kobotoolbox account. pwd Password Kobotoolbox account. encoding Encoding used data retrieval (default \"UTF-8\"). format Format data retrieve, either \"json\" \"xml\" (default \"json\").","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_kobo_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve Data from Kobotoolbox API — get_kobo_data","text":"list containing retrieved survey results.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_kobo_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Retrieve Data from Kobotoolbox API — get_kobo_data","text":"function uses pagination retrieve large datasets, limit 30,000 records per request. continues fetch data records retrieved error occurs.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_kobo_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Retrieve Data from Kobotoolbox API — get_kobo_data","text":"","code":"if (FALSE) { # \\dontrun{ kobo_data <- get_kobo_data(   assetid = \"your_asset_id\",   uname = \"your_username\",   pwd = \"your_password\" ) } # }"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_length_weight_batch.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Length-Weight and Morphological Parameters for Species (Batch Version) — get_length_weight_batch","title":"Get Length-Weight and Morphological Parameters for Species (Batch Version) — get_length_weight_batch","text":"Retrieves length-weight relationship parameters optional morphological data multiple species efficiently processing batches. Handles fish non-fish species appropriately.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_length_weight_batch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Length-Weight and Morphological Parameters for Species (Batch Version) — get_length_weight_batch","text":"","code":"get_length_weight_batch(species_areas_filtered, include_morphology = FALSE)"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_length_weight_batch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Length-Weight and Morphological Parameters for Species (Batch Version) — get_length_weight_batch","text":"species_areas_filtered Data frame filtered species include_morphology Logical, whether include morphological data (Length, CommonLength, Weight). Default FALSE.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_length_weight_batch.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Length-Weight and Morphological Parameters for Species (Batch Version) — get_length_weight_batch","text":"include_morphology FALSE (default), data frame columns: a3_code: FAO 3-alpha code species: Scientific name area_code: FAO area code database: Source database type: Measurement type (e.g., \"TL\" total length) : Length-weight parameter b: Length-weight parameter b include_morphology TRUE, list two elements: length_weight: Data frame described morphology: Data frame columns: a3_code: FAO 3-alpha code species: Scientific name area_code: FAO area code database: Source database Length: Maximum recorded length CommonLength: Common length Weight: Maximum weight","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_length_weight_batch.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Get Length-Weight and Morphological Parameters for Species (Batch Version) — get_length_weight_batch","text":"FishBase species, total length (TL) measurements used Questionable estimates (EsQ = \"yes\") excluded","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_length_weight_batch.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Length-Weight and Morphological Parameters for Species (Batch Version) — get_length_weight_batch","text":"","code":"if (FALSE) { # \\dontrun{ # Get just length-weight parameters lw_data <- get_length_weight_batch(species_areas_filtered)  # Get both length-weight and morphological data results <- get_length_weight_batch(species_areas_filtered, include_morphology = TRUE) lw_data <- results$length_weight morph_data <- results$morphology } # }"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_metadata.html","id":null,"dir":"Reference","previous_headings":"","what":"Get metadata tables — get_metadata","title":"Get metadata tables — get_metadata","text":"Get Metadata tables Google sheets. function downloads tables include information fishery.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_metadata.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get metadata tables — get_metadata","text":"","code":"get_metadata(log_threshold = logger::DEBUG)"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_metadata.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get metadata tables — get_metadata","text":"log_threshold logging threshold level. Default logger::DEBUG.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_metadata.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get metadata tables — get_metadata","text":"parameters needed conf.yml :","code":"storage:   storage_name:     key:     options:       project:       bucket:       service_account_key:"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_metadata.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get metadata tables — get_metadata","text":"","code":"if (FALSE) { # \\dontrun{ # Ensure you have the necessary configuration in conf.yml metadata_tables <- get_metadata() } # }"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_price_bounds.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Price Bounds by Gear + Taxon — get_price_bounds","title":"Get Price Bounds by Gear + Taxon — get_price_bounds","text":"Computes outlier bounds catch_price grouped interaction gear catch_taxon. default, applies logt = TRUE LocScaleB exponentiates resulting upper bound.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_price_bounds.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Price Bounds by Gear + Taxon — get_price_bounds","text":"","code":"get_price_bounds(data, k)"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_price_bounds.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Price Bounds by Gear + Taxon — get_price_bounds","text":"data data frame containing gear, catch_taxon, catch_price. k numeric parameter passed LocScaleB.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_price_bounds.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Price Bounds by Gear + Taxon — get_price_bounds","text":"data frame columns gear, catch_taxon, upper.representing exponentiated upper bound. lower.low column dropped.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_price_bounds.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get Price Bounds by Gear + Taxon — get_price_bounds","text":"Similar get_catch_bounds_taxon, operating catch_price rather catch_kg. Splits data gear + taxon, uses LocScaleB find outlier bounds, exponentiates upper bound.","code":""},{"path":[]},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_price_bounds.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Price Bounds by Gear + Taxon — get_price_bounds","text":"","code":"if (FALSE) { # \\dontrun{ price_bounds <- get_price_bounds(data, k = 3) head(price_bounds) } # }"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_species_areas_batch.html","id":null,"dir":"Reference","previous_headings":"","what":"Get FAO Areas for Species (Batch Version) — get_species_areas_batch","title":"Get FAO Areas for Species (Batch Version) — get_species_areas_batch","text":"Efficiently retrieves FAO areas multiple species processing batches database source, reducing API calls processing time.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_species_areas_batch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get FAO Areas for Species (Batch Version) — get_species_areas_batch","text":"","code":"get_species_areas_batch(matched_species)"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_species_areas_batch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get FAO Areas for Species (Batch Version) — get_species_areas_batch","text":"matched_species Data frame match_species_from_taxa()","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_species_areas_batch.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get FAO Areas for Species (Batch Version) — get_species_areas_batch","text":"data frame columns: a3_code: FAO 3-alpha code species: Scientific name area_code: FAO area code database: Source database","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_species_areas_batch.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get FAO Areas for Species (Batch Version) — get_species_areas_batch","text":"","code":"if (FALSE) { # \\dontrun{ species_areas <- get_species_areas_batch(matched_species) # Filter for specific FAO area area_51_species <- species_areas %>%   dplyr::filter(area_code == 51) } # }"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_total_catch_bounds.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Total Catch Bounds by Landing Site and Gear — get_total_catch_bounds","title":"Get Total Catch Bounds by Landing Site and Gear — get_total_catch_bounds","text":"Computes outlier bounds total catch (total_catch_kg) grouped combination landing_site gear. Internally, first aggregates catch_kg get single total_catch_kg per submission, applies LocScaleB (log transform) within site-gear group.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_total_catch_bounds.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Total Catch Bounds by Landing Site and Gear — get_total_catch_bounds","text":"","code":"get_total_catch_bounds(data, k)"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_total_catch_bounds.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Total Catch Bounds by Landing Site and Gear — get_total_catch_bounds","text":"data data frame containing submission_id, landing_site, gear, catch_kg. k numeric parameter passed LocScaleB.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_total_catch_bounds.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Total Catch Bounds by Landing Site and Gear — get_total_catch_bounds","text":"data frame columns: landing_site gear upper.(exponentiated upper bound)","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_total_catch_bounds.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get Total Catch Bounds by Landing Site and Gear — get_total_catch_bounds","text":"Groups submission_id, landing_site, gear sums catch_kg total_catch_kg. Splits results site-gear combination. Calls LocScaleB group, exponentiates upper.bound, returns data frame landing_site, gear, upper..","code":""},{"path":[]},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_total_catch_bounds.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Total Catch Bounds by Landing Site and Gear — get_total_catch_bounds","text":"","code":"if (FALSE) { # \\dontrun{ total_bounds <- get_total_catch_bounds(data, k = 3) head(total_bounds) } # }"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_trip_points.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Trip Points from Pelagic Data Systems API — get_trip_points","title":"Get Trip Points from Pelagic Data Systems API — get_trip_points","text":"Retrieves trip points data Pelagic Data Systems API. function can either fetch data specific trip ID date range. response can returned data frame written directly file.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_trip_points.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Trip Points from Pelagic Data Systems API — get_trip_points","text":"","code":"get_trip_points(   token = NULL,   secret = NULL,   id = NULL,   dateFrom = NULL,   dateTo = NULL,   path = NULL,   imeis = NULL,   deviceInfo = FALSE,   errant = FALSE,   withLastSeen = FALSE,   tags = NULL,   overwrite = TRUE )"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_trip_points.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Trip Points from Pelagic Data Systems API — get_trip_points","text":"token Character string. Access token PDS API. secret Character string. Secret key PDS API. id Numeric character. Optional trip ID. provided, retrieves points specific trip. NULL, dateFrom dateTo must provided. dateFrom Character string. Start date data retrieval format \"YYYY-MM-DD\". Required id NULL. dateTo Character string. End date data retrieval format \"YYYY-MM-DD\". Required id NULL. path Character string. Optional path CSV file saved. provided, function returns path instead data frame. imeis Vector character numeric. Optional IMEI numbers filter data. deviceInfo Logical. TRUE, includes device information response. Default FALSE. errant Logical. TRUE, includes errant points response. Default FALSE. withLastSeen Logical. TRUE, includes last seen information. Default FALSE. tags Vector character. Optional tags filter data. overwrite Logical. TRUE, overwrite existing file path provided. Default TRUE.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_trip_points.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Trip Points from Pelagic Data Systems API — get_trip_points","text":"path NULL, returns tibble containing trip points data. path provided, returns file path character string.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_trip_points.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Trip Points from Pelagic Data Systems API — get_trip_points","text":"","code":"if (FALSE) { # \\dontrun{ # Get data for a specific trip trip_data <- get_trip_points(   token = \"your_token\",   secret = \"your_secret\",   id = \"12345\",   deviceInfo = TRUE )  # Get data for a date range date_data <- get_trip_points(   token = \"your_token\",   secret = \"your_secret\",   dateFrom = \"2024-01-01\",   dateTo = \"2024-01-31\" )  # Save data directly to file file_path <- get_trip_points(   token = \"your_token\",   secret = \"your_secret\",   id = \"12345\",   path = \"trip_data.csv\" ) } # }"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_trips.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve Trip Details from Pelagic Data API — get_trips","title":"Retrieve Trip Details from Pelagic Data API — get_trips","text":"function retrieves trip details Pelagic Data API specified time range, options filter IMEIs include additional information.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_trips.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve Trip Details from Pelagic Data API — get_trips","text":"","code":"get_trips(   token = NULL,   secret = NULL,   dateFrom = NULL,   dateTo = NULL,   imeis = NULL,   deviceInfo = FALSE,   withLastSeen = FALSE,   tags = NULL )"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_trips.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve Trip Details from Pelagic Data API — get_trips","text":"token Character string. API token authentication. secret Character string. API secret authentication. dateFrom Character string. Start date 'YYYY-MM-dd' format. dateTo Character string. End date 'YYYY-MM-dd' format. imeis Character vector. Optional. Filter IMEI numbers. deviceInfo Logical. TRUE, include device IMEI ID fields response. Default FALSE. withLastSeen Logical. TRUE, include device last seen date response. Default FALSE. tags Character vector. Optional. Filter trip tags.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_trips.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve Trip Details from Pelagic Data API — get_trips","text":"data frame containing trip details.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_trips.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Retrieve Trip Details from Pelagic Data API — get_trips","text":"","code":"if (FALSE) { # \\dontrun{ trips <- get_trips(   token = \"your_token\",   secret = \"your_secret\",   dateFrom = \"2020-05-01\",   dateTo = \"2020-05-03\",   imeis = c(\"123456789\", \"987654321\"),   deviceInfo = TRUE,   withLastSeen = TRUE,   tags = c(\"tag1\", \"tag2\") ) } # }"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_validation_status.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Validation Status from KoboToolbox — get_validation_status","title":"Get Validation Status from KoboToolbox — get_validation_status","text":"Retrieves validation status specific submission KoboToolbox. function handles NULL responses returns consistent tibble structure regardless API response.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_validation_status.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Validation Status from KoboToolbox — get_validation_status","text":"","code":"get_validation_status(   submission_id = NULL,   asset_id = NULL,   token = NULL,   debug = FALSE )"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_validation_status.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Validation Status from KoboToolbox — get_validation_status","text":"submission_id Character string. ID submission check. asset_id Character string. asset ID KoboToolbox. token Character string. authorization token KoboToolbox API. debug Logical. TRUE, prints request object. Default FALSE.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_validation_status.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Validation Status from KoboToolbox — get_validation_status","text":"tibble one row containing: submission_id ID checked submission validation_status validation status (e.g., \"validation_status_approved\" \"not_validated\") validated_at Timestamp validation POSIXct validated_by Username validator","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_validation_status.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Validation Status from KoboToolbox — get_validation_status","text":"","code":"if (FALSE) { # \\dontrun{ # Single submission get_validation_status(   submission_id = \"1234567\",   asset_id = \"your asset id\",   token = \"Token YOUR_TOKEN_HERE\" )  # Multiple submissions using purrr submission_ids <- c(\"1234567\", \"154267\") submission_ids %>%   purrr::map_dfr(get_validation_status,     asset_id = \"your asset id\",     token = \"Token YOUR_TOKEN_HERE\"   ) } # }"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_writable_fields.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Writable Fields from Airtable Table — get_writable_fields","title":"Get Writable Fields from Airtable Table — get_writable_fields","text":"Returns fields can updated (excludes computed fields).","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_writable_fields.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Writable Fields from Airtable Table — get_writable_fields","text":"","code":"get_writable_fields(base_id, token, table_name)"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_writable_fields.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Writable Fields from Airtable Table — get_writable_fields","text":"base_id Character string. Airtable base ID. token Character string. Airtable API token. table_name Character string. Name table.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/get_writable_fields.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Writable Fields from Airtable Table — get_writable_fields","text":"Character vector writable field names.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/ingest_landings_adnap.html","id":null,"dir":"Reference","previous_headings":"","what":"Download and Process ADNAP Surveys from Kobotoolbox — ingest_landings_adnap","title":"Download and Process ADNAP Surveys from Kobotoolbox — ingest_landings_adnap","text":"function retrieves ADNAP survey data Kobotoolbox, processes , uploads raw data Google Cloud Storage Parquet files. uses get_kobo_data function retrieve survey submissions via Kobotoolbox API.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/ingest_landings_adnap.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download and Process ADNAP Surveys from Kobotoolbox — ingest_landings_adnap","text":"","code":"ingest_landings_adnap()"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/ingest_landings_adnap.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download and Process ADNAP Surveys from Kobotoolbox — ingest_landings_adnap","text":"Invisible NULL. Function downloads data, processes , uploads Google Cloud Storage.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/ingest_landings_adnap.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Download and Process ADNAP Surveys from Kobotoolbox — ingest_landings_adnap","text":"function performs following steps: Reads configuration settings config.yml Downloads survey data Kobotoolbox using get_kobo_data Checks uniqueness submissions Flattens nested JSON data tabular format Uploads raw data versioned Parquet file Google Cloud Storage","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/ingest_landings_adnap.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Download and Process ADNAP Surveys from Kobotoolbox — ingest_landings_adnap","text":"function uses configuration values config.yml: Hardcoded URL: \"eu.kobotoolbox.org\" Hardcoded encoding: \"UTF-8\" Configuration values : asset_id, username, password (shared Lurio) GCS bucket credentials configuration","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/ingest_landings_adnap.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download and Process ADNAP Surveys from Kobotoolbox — ingest_landings_adnap","text":"","code":"if (FALSE) { # \\dontrun{ ingest_landings_adnap() } # }"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/ingest_landings_lurio.html","id":null,"dir":"Reference","previous_headings":"","what":"Download and Process Lurio Surveys from Kobotoolbox — ingest_landings_lurio","title":"Download and Process Lurio Surveys from Kobotoolbox — ingest_landings_lurio","text":"function retrieves Lurio survey data Kobotoolbox, processes , uploads raw data Google Cloud Storage Parquet files. uses get_kobo_data function retrieve survey submissions via Kobotoolbox API.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/ingest_landings_lurio.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download and Process Lurio Surveys from Kobotoolbox — ingest_landings_lurio","text":"","code":"ingest_landings_lurio()"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/ingest_landings_lurio.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download and Process Lurio Surveys from Kobotoolbox — ingest_landings_lurio","text":"Invisible NULL. Function downloads data, processes , uploads Google Cloud Storage.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/ingest_landings_lurio.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Download and Process Lurio Surveys from Kobotoolbox — ingest_landings_lurio","text":"function performs following steps: Reads configuration settings config.yml Downloads survey data Kobotoolbox using get_kobo_data Checks uniqueness submissions Flattens nested JSON data tabular format Uploads raw data versioned Parquet file Google Cloud Storage","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/ingest_landings_lurio.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Download and Process Lurio Surveys from Kobotoolbox — ingest_landings_lurio","text":"function uses configuration values config.yml: Hardcoded URL: \"eu.kobotoolbox.org\" Hardcoded encoding: \"UTF-8\" Configuration values : asset_id, username, password GCS bucket credentials configuration","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/ingest_landings_lurio.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download and Process Lurio Surveys from Kobotoolbox — ingest_landings_lurio","text":"","code":"if (FALSE) { # \\dontrun{ ingest_landings_lurio() } # }"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/ingest_pds_tracks.html","id":null,"dir":"Reference","previous_headings":"","what":"Ingest Pelagic Data Systems (PDS) Track Data — ingest_pds_tracks","title":"Ingest Pelagic Data Systems (PDS) Track Data — ingest_pds_tracks","text":"function handles automated ingestion GPS boat track data Pelagic Data Systems (PDS). downloads stores new tracks previously uploaded Google Cloud Storage. Uses parallel processing improved performance.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/ingest_pds_tracks.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Ingest Pelagic Data Systems (PDS) Track Data — ingest_pds_tracks","text":"","code":"ingest_pds_tracks(log_threshold = logger::DEBUG, batch_size = NULL)"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/ingest_pds_tracks.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Ingest Pelagic Data Systems (PDS) Track Data — ingest_pds_tracks","text":"log_threshold logging threshold use. Default logger::DEBUG. batch_size Optional number tracks process. NULL, processes new tracks.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/ingest_pds_tracks.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Ingest Pelagic Data Systems (PDS) Track Data — ingest_pds_tracks","text":"None (invisible). function performs operations side effects.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/ingest_pds_trips.html","id":null,"dir":"Reference","previous_headings":"","what":"Ingest Pelagic Data Systems (PDS) Trip Data — ingest_pds_trips","title":"Ingest Pelagic Data Systems (PDS) Trip Data — ingest_pds_trips","text":"function handles automated ingestion GPS boat trip data Pelagic Data Systems (PDS). performs following operations: Retrieves device metadata configured source Downloads trip data PDS API using device IMEIs Converts data parquet format Uploads processed file configured cloud storage","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/ingest_pds_trips.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Ingest Pelagic Data Systems (PDS) Trip Data — ingest_pds_trips","text":"","code":"ingest_pds_trips(log_threshold = logger::DEBUG)"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/ingest_pds_trips.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Ingest Pelagic Data Systems (PDS) Trip Data — ingest_pds_trips","text":"log_threshold logging threshold use. Default logger::DEBUG. See logger::log_levels available options.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/ingest_pds_trips.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Ingest Pelagic Data Systems (PDS) Trip Data — ingest_pds_trips","text":"None (invisible). function performs operations side effects: Creates parquet file locally trip data Uploads file configured cloud storage Generates logs process","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/ingest_pds_trips.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Ingest Pelagic Data Systems (PDS) Trip Data — ingest_pds_trips","text":"function requires specific configuration conf.yml file following structure:   function processes trips sequentially: Retrieves device metadata using get_metadata() Downloads trip data using get_trips() function Converts data parquet format Uploads resulting file configured storage provider","code":"pds:   token: \"your_pds_token\"               # PDS API token   secret: \"your_pds_secret\"             # PDS API secret   pds_trips:     file_prefix: \"pds_trips\"            # Prefix for output files storage:   google:                               # Storage provider name     key: \"google\"                       # Storage provider identifier     options:       project: \"project-id\"             # Cloud project ID       bucket: \"bucket-name\"             # Storage bucket name       service_account_key: \"path/to/key.json\""},{"path":[]},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/ingest_pds_trips.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Ingest Pelagic Data Systems (PDS) Trip Data — ingest_pds_trips","text":"","code":"if (FALSE) { # \\dontrun{ # Run with default debug logging ingest_pds_trips()  # Run with info-level logging only ingest_pds_trips(logger::INFO) } # }"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/load_dotenv.html","id":null,"dir":"Reference","previous_headings":"","what":"Load environment variables from .env file — load_dotenv","title":"Load environment variables from .env file — load_dotenv","text":"Loads environment variables .env file exists. function called reading configuration ensure dotenv variables available.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/load_dotenv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load environment variables from .env file — load_dotenv","text":"","code":"load_dotenv(file = \".env\")"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/load_dotenv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load environment variables from .env file — load_dotenv","text":"file Path .env file, defaults \".env\" current working directory","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/load_dotenv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Load environment variables from .env file — load_dotenv","text":"NULL (called side effects)","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/load_taxa_databases.html","id":null,"dir":"Reference","previous_headings":"","what":"Load Taxa Data from FishBase and SeaLifeBase — load_taxa_databases","title":"Load Taxa Data from FishBase and SeaLifeBase — load_taxa_databases","text":"Retrieves taxonomic data FishBase SeaLifeBase databases single function call. typically first step species identification classification.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/load_taxa_databases.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load Taxa Data from FishBase and SeaLifeBase — load_taxa_databases","text":"","code":"load_taxa_databases()"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/load_taxa_databases.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Load Taxa Data from FishBase and SeaLifeBase — load_taxa_databases","text":"list two elements: fishbase: Data frame containing FishBase taxonomic data sealifebase: Data frame containing SeaLifeBase taxonomic data","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/load_taxa_databases.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Load Taxa Data from FishBase and SeaLifeBase — load_taxa_databases","text":"","code":"if (FALSE) { # \\dontrun{ taxa_data <- load_taxa_databases() fishbase_taxa <- taxa_data$fishbase sealifebase_taxa <- taxa_data$sealifebase } # }"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/map_surveys.html","id":null,"dir":"Reference","previous_headings":"","what":"Map Survey Labels to Standardized Taxa, Gear, and Vessel Names — map_surveys","title":"Map Survey Labels to Standardized Taxa, Gear, and Vessel Names — map_surveys","text":"Converts local species, gear, vessel labels surveys standardized names using Airtable reference tables. Replaces catch_taxon scientific_name alpha3_code, replaces local gear vessel names standardized types.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/map_surveys.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Map Survey Labels to Standardized Taxa, Gear, and Vessel Names — map_surveys","text":"","code":"map_surveys(   data = NULL,   taxa_mapping = NULL,   gear_mapping = NULL,   vessels_mapping = NULL,   sites_mapping = NULL )"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/map_surveys.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Map Survey Labels to Standardized Taxa, Gear, and Vessel Names — map_surveys","text":"data data frame preprocessed survey data containing catch_taxon, gear, vessel_type, landing_site columns. taxa_mapping data frame Airtable taxa table survey_label, alpha3_code, scientific_name columns. gear_mapping data frame Airtable gears table survey_label standard_name columns. vessels_mapping data frame Airtable vessels table survey_label standard_name columns. sites_mapping data frame Airtable landing_sites table site_code site columns.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/map_surveys.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Map Survey Labels to Standardized Taxa, Gear, and Vessel Names — map_surveys","text":"tibble catch_taxon replaced scientific_name alpha3_code, gear vessel_type replaced standardized names, landing_site replaced full site name. Records without matches NA values.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/map_surveys.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Map Survey Labels to Standardized Taxa, Gear, and Vessel Names — map_surveys","text":"function called within preprocess_landings() processing raw survey data. mapping tables retrieved Airtable frame base filtered form ID passed function.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/match_species_from_taxa.html","id":null,"dir":"Reference","previous_headings":"","what":"Match Species from Taxa Databases — match_species_from_taxa","title":"Match Species from Taxa Databases — match_species_from_taxa","text":"Matches species FAO codes database records, handling different taxonomic levels (species, genus, family, order) appropriately.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/match_species_from_taxa.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Match Species from Taxa Databases — match_species_from_taxa","text":"","code":"match_species_from_taxa(species_list, taxa_data)"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/match_species_from_taxa.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Match Species from Taxa Databases — match_species_from_taxa","text":"species_list Processed species list process_species_list() taxa_data Taxa data load_taxa_databases()","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/match_species_from_taxa.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Match Species from Taxa Databases — match_species_from_taxa","text":"data frame columns: a3_code: FAO 3-alpha code species: Scientific name database: Source database","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/match_species_from_taxa.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Match Species from Taxa Databases — match_species_from_taxa","text":"","code":"if (FALSE) { # \\dontrun{ taxa_data <- load_taxa_databases() species_list <- process_species_list(fao_codes, asfis) matches <- match_species_from_taxa(species_list, taxa_data) } # }"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/mdb_collection_pull.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve Data from MongoDB — mdb_collection_pull","title":"Retrieve Data from MongoDB — mdb_collection_pull","text":"function connects MongoDB database retrieves documents specified collection, maintaining original column order available.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/mdb_collection_pull.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve Data from MongoDB — mdb_collection_pull","text":"","code":"mdb_collection_pull(   connection_string = NULL,   collection_name = NULL,   db_name = NULL )"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/mdb_collection_pull.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve Data from MongoDB — mdb_collection_pull","text":"connection_string character string specifying MongoDB connection URL. Default NULL. collection_name character string specifying name collection query. Default NULL. db_name character string specifying name database. Default NULL.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/mdb_collection_pull.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve Data from MongoDB — mdb_collection_pull","text":"data frame containing documents specified collection, columns ordered data originally pushed MongoDB.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/mdb_collection_pull.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Retrieve Data from MongoDB — mdb_collection_pull","text":"","code":"if (FALSE) { # \\dontrun{ # Retrieve data from a MongoDB collection result <- mdb_collection_pull(   connection_string = \"mongodb://localhost:27017\",   collection_name = \"my_collection\",   db_name = \"my_database\" ) } # }"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/mdb_collection_push.html","id":null,"dir":"Reference","previous_headings":"","what":"Upload Data to MongoDB and Overwrite Existing Content — mdb_collection_push","title":"Upload Data to MongoDB and Overwrite Existing Content — mdb_collection_push","text":"function connects MongoDB database, removes existing documents specified collection, inserts new data. also stores original column order maintain data structure consistency.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/mdb_collection_push.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Upload Data to MongoDB and Overwrite Existing Content — mdb_collection_push","text":"","code":"mdb_collection_push(   data = NULL,   connection_string = NULL,   collection_name = NULL,   db_name = NULL )"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/mdb_collection_push.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Upload Data to MongoDB and Overwrite Existing Content — mdb_collection_push","text":"data data frame containing data uploaded. connection_string character string specifying MongoDB connection URL. collection_name character string specifying name collection. db_name character string specifying name database.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/mdb_collection_push.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Upload Data to MongoDB and Overwrite Existing Content — mdb_collection_push","text":"number data documents inserted collection (excluding order document).","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/mdb_collection_push.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Upload Data to MongoDB and Overwrite Existing Content — mdb_collection_push","text":"","code":"if (FALSE) { # \\dontrun{ # Upload and overwrite data in a MongoDB collection result <- mdb_collection_push(   data = processed_legacy_landings,   connection_string = \"mongodb://localhost:27017\",   collection_name = \"my_collection\",   db_name = \"my_database\" ) } # }"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/peskas.mozambique.data.pipeline-package.html","id":null,"dir":"Reference","previous_headings":"","what":"peskas.mozambique.data.pipeline: What the Package Does (One Line, Title Case) — peskas.mozambique.data.pipeline-package","title":"peskas.mozambique.data.pipeline: What the Package Does (One Line, Title Case) — peskas.mozambique.data.pipeline-package","text":"package (one paragraph).","code":""},{"path":[]},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/peskas.mozambique.data.pipeline-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"peskas.mozambique.data.pipeline: What the Package Does (One Line, Title Case) — peskas.mozambique.data.pipeline-package","text":"Maintainer: First Last first.last@example.com (ORCID)","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/pipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pipe operator — %>%","text":"lhs value magrittr placeholder. rhs function call using magrittr semantics.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/pipe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pipe operator — %>%","text":"result calling rhs(lhs).","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/preprocess_catch.html","id":null,"dir":"Reference","previous_headings":"","what":"Preprocess Catch Data from Survey Forms — preprocess_catch","title":"Preprocess Catch Data from Survey Forms — preprocess_catch","text":"Processes catch data KoBoToolbox survey forms, handling different field structures result various survey form configurations. Automatically normalizes species field variations processes length group data.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/preprocess_catch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Preprocess Catch Data from Survey Forms — preprocess_catch","text":"","code":"preprocess_catch(data = NULL)"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/preprocess_catch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Preprocess Catch Data from Survey Forms — preprocess_catch","text":"data data frame containing raw survey data species groups","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/preprocess_catch.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Preprocess Catch Data from Survey Forms — preprocess_catch","text":"data frame processed catch data including: submission_id, n_catch, count_method, catch_taxon, n_buckets, weight_bucket, individuals, length, catch_weight","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/preprocess_catch.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Preprocess Catch Data from Survey Forms — preprocess_catch","text":"function uses reshape_catch_data() internally automatically handles: Multiple species field formats (species_TL, species_RF, species_SH, etc.) Separate length group structures fish 100cm Length range conversion midpoint values Species code standardization (e.g., TUN→TUS, SKH→CVX)","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/preprocess_general_adnap.html","id":null,"dir":"Reference","previous_headings":"","what":"Preprocess General Survey Information for ADNAP — preprocess_general_adnap","title":"Preprocess General Survey Information for ADNAP — preprocess_general_adnap","text":"Processes general survey information ADNAP KoBoToolbox forms including trip details, fisher counts, vessel information, survey metadata.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/preprocess_general_adnap.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Preprocess General Survey Information for ADNAP — preprocess_general_adnap","text":"","code":"preprocess_general_adnap(data = NULL)"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/preprocess_general_adnap.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Preprocess General Survey Information for ADNAP — preprocess_general_adnap","text":"data data frame containing raw ADNAP survey data","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/preprocess_general_adnap.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Preprocess General Survey Information for ADNAP — preprocess_general_adnap","text":"data frame processed general survey information including: submission_id, dates, location, gear, trip details, fisher counts, etc.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/preprocess_landings_adnap.html","id":null,"dir":"Reference","previous_headings":"","what":"Preprocess ADNAP Landings Data — preprocess_landings_adnap","title":"Preprocess ADNAP Landings Data — preprocess_landings_adnap","text":"function preprocesses raw ADNAP survey data Google Cloud Storage. performs data cleaning, transformation, catch weight calculations using length-weight relationships, uploads processed data back GCS.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/preprocess_landings_adnap.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Preprocess ADNAP Landings Data — preprocess_landings_adnap","text":"","code":"preprocess_landings_adnap(log_threshold = logger::DEBUG)"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/preprocess_landings_adnap.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Preprocess ADNAP Landings Data — preprocess_landings_adnap","text":"log_threshold Logging threshold level (default: logger::DEBUG)","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/preprocess_landings_adnap.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Preprocess ADNAP Landings Data — preprocess_landings_adnap","text":"Invisible NULL. Function processes data uploads Google Cloud Storage.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/preprocess_landings_adnap.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Preprocess ADNAP Landings Data — preprocess_landings_adnap","text":"function performs following main operations: Downloads ASFIS species data Airtable form assets GCS Downloads raw survey data GCS Parquet file Processes general trip information using preprocess_general_adnap() Processes catch data using preprocess_catch() handles survey version detection Calculates catch weights via calculate_catch_adnap() using length-weight coefficients Joins trip catch data Maps survey codes standardized names using Airtable assets Uploads preprocessed data versioned Parquet file GCS","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/preprocess_landings_adnap.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Preprocess ADNAP Landings Data — preprocess_landings_adnap","text":"","code":"if (FALSE) { # \\dontrun{ preprocess_landings_adnap() } # }"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/preprocess_landings_lurio.html","id":null,"dir":"Reference","previous_headings":"","what":"Preprocess Lurio Landings Data — preprocess_landings_lurio","title":"Preprocess Lurio Landings Data — preprocess_landings_lurio","text":"function preprocesses raw Lurio survey data Google Cloud Storage. performs data cleaning, transformation, catch weight calculations using length-weight relationships, uploads processed data back GCS.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/preprocess_landings_lurio.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Preprocess Lurio Landings Data — preprocess_landings_lurio","text":"","code":"preprocess_landings_lurio(log_threshold = logger::DEBUG)"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/preprocess_landings_lurio.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Preprocess Lurio Landings Data — preprocess_landings_lurio","text":"log_threshold Logging threshold level (default: logger::DEBUG)","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/preprocess_landings_lurio.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Preprocess Lurio Landings Data — preprocess_landings_lurio","text":"Invisible NULL. Function processes data uploads Google Cloud Storage.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/preprocess_landings_lurio.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Preprocess Lurio Landings Data — preprocess_landings_lurio","text":"function performs following main operations: Downloads ASFIS species data Airtable form assets GCS Downloads raw survey data GCS Parquet file Extracts processes general trip information (dates, location, GPS) Extracts processes trip details (vessel, gear, fishers, duration) Processes catch data using process_species_group() reshape wide long format Calculates catch weights via calculate_catch_lurio() using length-weight coefficients Processes market information (catch use price) Joins datasets filters active surveys Maps survey codes standardized names using Airtable assets Uploads preprocessed data versioned Parquet file GCS","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/preprocess_landings_lurio.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Preprocess Lurio Landings Data — preprocess_landings_lurio","text":"","code":"if (FALSE) { # \\dontrun{ preprocess_landings_lurio() } # }"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/preprocess_pds_tracks.html","id":null,"dir":"Reference","previous_headings":"","what":"Preprocess Pelagic Data Systems (PDS) Track Data — preprocess_pds_tracks","title":"Preprocess Pelagic Data Systems (PDS) Track Data — preprocess_pds_tracks","text":"Downloads raw GPS tracks creates gridded summary fishing activity.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/preprocess_pds_tracks.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Preprocess Pelagic Data Systems (PDS) Track Data — preprocess_pds_tracks","text":"","code":"preprocess_pds_tracks(log_threshold = logger::DEBUG, grid_size = 500)"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/preprocess_pds_tracks.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Preprocess Pelagic Data Systems (PDS) Track Data — preprocess_pds_tracks","text":"log_threshold logging threshold use. Default logger::DEBUG. grid_size Numeric. Size grid cells meters (100, 250, 500, 1000).","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/preprocess_pds_tracks.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Preprocess Pelagic Data Systems (PDS) Track Data — preprocess_pds_tracks","text":"None (invisible). Creates uploads preprocessed files.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/preprocess_track_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Preprocess Track Data into Spatial Grid Summary — preprocess_track_data","title":"Preprocess Track Data into Spatial Grid Summary — preprocess_track_data","text":"function processes GPS track data spatial grid summary, calculating time spent metrics grid cell. grid size can specified analyze spatial patterns different scales.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/preprocess_track_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Preprocess Track Data into Spatial Grid Summary — preprocess_track_data","text":"","code":"preprocess_track_data(data, grid_size = 500)"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/preprocess_track_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Preprocess Track Data into Spatial Grid Summary — preprocess_track_data","text":"data data frame containing GPS track data columns: Trip: Unique trip identifier Time: Timestamp GPS point Lat: Latitude Lng: Longitude Speed (M/S): Speed meters per second Range (Meters): Range meters Heading: Heading degrees grid_size Numeric. Size grid cells meters. Must one : 100: ~100m grid cells 250: ~250m grid cells 500: ~500m grid cells (default) 1000: ~1km grid cells","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/preprocess_track_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Preprocess Track Data into Spatial Grid Summary — preprocess_track_data","text":"tibble following columns: Trip: Trip identifier lat_grid: Latitude grid cell center lng_grid: Longitude grid cell center time_spent_mins: Total time spent grid cell minutes mean_speed: Average speed grid cell (M/S) mean_range: Average range grid cell (Meters) first_seen: First timestamp grid cell last_seen: Last timestamp grid cell n_points: Number GPS points grid cell","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/preprocess_track_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Preprocess Track Data into Spatial Grid Summary — preprocess_track_data","text":"function creates grid rounding coordinates based specified grid size. Grid sizes approximate due conversion meters degrees, calculations based 1 degree ≈ 111km equator. Time spent calculated using time differences consecutive points.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/preprocess_track_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Preprocess Track Data into Spatial Grid Summary — preprocess_track_data","text":"","code":"if (FALSE) { # \\dontrun{ # Process tracks with 500m grid (default) result_500m <- preprocess_track_data(tracks_data)  # Use 100m grid for finer resolution result_100m <- preprocess_track_data(tracks_data, grid_size = 100)  # Use 1km grid for broader patterns result_1km <- preprocess_track_data(tracks_data, grid_size = 1000) } # }"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/process_single_track.html","id":null,"dir":"Reference","previous_headings":"","what":"Process Single PDS Track — process_single_track","title":"Process Single PDS Track — process_single_track","text":"Process Single PDS Track","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/process_single_track.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process Single PDS Track — process_single_track","text":"","code":"process_single_track(trip_id, conf)"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/process_single_track.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process Single PDS Track — process_single_track","text":"trip_id Character. ID trip process. conf List. Configuration parameters.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/process_single_track.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process Single PDS Track — process_single_track","text":"List processing status details.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/process_species_group.html","id":null,"dir":"Reference","previous_headings":"","what":"Process Species Length and Catch Data — process_species_group","title":"Process Species Length and Catch Data — process_species_group","text":"Processes raw survey data extract organize species information, length measurements, catch estimates. Handles empty non-empty submissions, converting wide-format survey data structured list tibbles.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/process_species_group.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process Species Length and Catch Data — process_species_group","text":"","code":"process_species_group(data = NULL)"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/process_species_group.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process Species Length and Catch Data — process_species_group","text":"data data frame containing raw survey data required columns: submission_id: Unique identifier submission group_species_*: Species information columns Optional: no_individuals_, fish_length_over, catch_estimate columns","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/process_species_group.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process Species Length and Catch Data — process_species_group","text":"list tibbles, one per submission_id, containing: Basic information: submission_id, species data, catch estimates Length data: available, includes length classes measurements Empty submissions: Preserved NA values","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/process_species_group.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process Species Length and Catch Data — process_species_group","text":"","code":"if (FALSE) { # \\dontrun{ results <- process_species_group(raw_dat) submission_data <- results[[\"1234\"]] } # }"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/process_species_list.html","id":null,"dir":"Reference","previous_headings":"","what":"Process Species List with Taxonomic Information — process_species_list","title":"Process Species List with Taxonomic Information — process_species_list","text":"Processes list species assigning database sources taxonomic ranks. Determines whether species looked FishBase SeaLifeBase based ISSCAAP group.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/process_species_list.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process Species List with Taxonomic Information — process_species_list","text":"","code":"process_species_list(fao_codes, asfis_list)"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/process_species_list.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process Species List with Taxonomic Information — process_species_list","text":"fao_codes Vector FAO 3-alpha codes asfis_list ASFIS list data frame containing taxonomic information","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/process_species_list.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process Species List with Taxonomic Information — process_species_list","text":"data frame columns: a3_code: FAO 3-alpha code scientific_name: Scientific name (cleaned) database: \"fishbase\" \"sealifebase\" rank: Taxonomic rank (\"Genus\", \"Family\", \"Order\", \"Species\") ... (taxonomic fields)","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/process_species_list.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Process Species List with Taxonomic Information — process_species_list","text":"ISSCAAP groups 57, 45, 43, 42, 56 assigned SeaLifeBase; others FishBase","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/process_species_list.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process Species List with Taxonomic Information — process_species_list","text":"","code":"if (FALSE) { # \\dontrun{ species_list <- process_species_list(c(\"TUN\", \"PEZ\"), asfis_data) } # }"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/process_submissions_parallel.html","id":null,"dir":"Reference","previous_headings":"","what":"Process Submissions in Parallel with Rate Limiting — process_submissions_parallel","title":"Process Submissions in Parallel with Rate Limiting — process_submissions_parallel","text":"Helper function process list submission IDs parallel built-rate limiting avoid overwhelming KoboToolbox API. function used internally validation sync functions apply operations submissions respecting API constraints.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/process_submissions_parallel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process Submissions in Parallel with Rate Limiting — process_submissions_parallel","text":"","code":"process_submissions_parallel(   submission_ids,   process_fn,   description = \"submissions\",   rate_limit = 0.2 )"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/process_submissions_parallel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process Submissions in Parallel with Rate Limiting — process_submissions_parallel","text":"submission_ids Character vector submission IDs process process_fn Function apply submission ID. accept single submission_id parameter return tibble results. description Character string describing type submissions processed (used log messages). Default \"submissions\". rate_limit Numeric value specifying delay seconds API calls. Default 0.2 seconds. Adjust based API rate limits.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/process_submissions_parallel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process Submissions in Parallel with Rate Limiting — process_submissions_parallel","text":"tibble containing combined results processed submissions. process_fn returns update_success column, failures logged.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/process_submissions_parallel.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Process Submissions in Parallel with Rate Limiting — process_submissions_parallel","text":"function uses parallel processing via furrr intentional delays requests prevent overwhelming API server. includes progress tracking optional failure logging result includes update_success column. Key features: Parallel execution using existing future plan Rate limiting via Sys.sleep() requests Progress tracking via progressr Automatic failure detection logging Returns combined results data frame","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/process_submissions_parallel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process Submissions in Parallel with Rate Limiting — process_submissions_parallel","text":"","code":"if (FALSE) { # \\dontrun{ # Setup parallel processing first future::plan(future::multisession, workers = 4)  # Fetch validation status for multiple submissions results <- process_submissions_parallel(   submission_ids = c(\"123\", \"456\", \"789\"),   process_fn = function(id) {     get_validation_status(       submission_id = id,       asset_id = \"your_asset_id\",       token = \"your_token\"     )   },   description = \"validation statuses\",   rate_limit = 0.1 )  # Update validation status for multiple submissions update_results <- process_submissions_parallel(   submission_ids = c(\"123\", \"456\"),   process_fn = function(id) {     update_validation_status(       submission_id = id,       status = \"validation_status_approved\",       asset_id = \"your_asset_id\",       token = \"your_token\"     )   },   description = \"approval updates\",   rate_limit = 0.2 ) } # }"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/process_version_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Process Version Data Helper Function — process_version_data","title":"Process Version Data Helper Function — process_version_data","text":"Internal helper function process catch general info specific survey version","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/process_version_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process Version Data Helper Function — process_version_data","text":"","code":"process_version_data(catch_info = NULL, asfis = NULL)"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/process_version_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process Version Data Helper Function — process_version_data","text":"catch_info Processed catch information asfis ASFIS species data","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/process_version_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process Version Data Helper Function — process_version_data","text":"Combined processed survey data","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/read_config.html","id":null,"dir":"Reference","previous_headings":"","what":"Read configuration file — read_config","title":"Read configuration file — read_config","text":"Reads configuration file config.yml adds logging lines. Also loads environment variables .env file present. Wrapped convenience","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/read_config.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read configuration file — read_config","text":"","code":"read_config()"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/read_config.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read configuration file — read_config","text":"environment parameters","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/rename_child.html","id":null,"dir":"Reference","previous_headings":"","what":"Rename Nested Survey Data Elements — rename_child","title":"Rename Nested Survey Data Elements — rename_child","text":"Appends parent name index child elements within nested list, assisting creating coherent traceable data structure flattening process.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/rename_child.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rename Nested Survey Data Elements — rename_child","text":"","code":"rename_child(x, i, p)"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/rename_child.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Rename Nested Survey Data Elements — rename_child","text":"x list element, possibly nested, renamed. index key element within parent list. p parent name prepend element's existing name context.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/rename_child.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Rename Nested Survey Data Elements — rename_child","text":"renamed list element, structured maintain contextual relevance flattened dataset.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/reshape_catch_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Reshape Catch Data with Length Groupings — reshape_catch_data","title":"Reshape Catch Data with Length Groupings — reshape_catch_data","text":"function takes KoBoToolbox survey data species catch information reshapes long format properly handling nested length group information. supports survey forms fish 100cm stored separate repeated group structures.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/reshape_catch_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reshape Catch Data with Length Groupings — reshape_catch_data","text":"","code":"reshape_catch_data(df = NULL)"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/reshape_catch_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reshape Catch Data with Length Groupings — reshape_catch_data","text":"df data frame containing catch data species groups length information. Expected columns following pattern: species_group.X columns (X position number) Multiple species fields within group (species_TL, species_RF, species_SH, etc.) Optional length group columns (species_group/no_fish_by_length_group_100/)","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/reshape_catch_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reshape Catch Data with Length Groupings — reshape_catch_data","text":"data frame long format row representing species catch record. output includes columns: - submission_id: Unique survey submission identifier - n_catch: Catch record number within submission (1-based) - counting_method: Method used count/measure catch - species: FAO 3-alpha species code (normalized multiple species_* fields) - n_buckets, weight_bucket, catch_weight: Bucket-based measurements - length_range: Length category (e.g., \"5_10\", \"over100\") - length_over: Specific length fish 100cm - count: Number individuals length range","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/reshape_catch_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Reshape Catch Data with Length Groupings — reshape_catch_data","text":"function performs following steps: Reshapes species groups wide long using reshape_species_groups() Normalizes multiple species fields (species_TL teleosts, species_RF rays/fish, species_SH sharks, species_FSH finfish, species_CRB crabs, species_CE cephalopods, species_LO lobster, species_CR crustacea, species_MA marine animals, species_OY oysters, species_FI fish, species_FFI flatfish, species_RA rays, species_SHK sharks, species_MZZ miscellaneous) single 'species' column Processes separate length group data fish 100cm available Combines length data species metadata Handles submissions without length data appropriately fish 100cm, function extracts specific length measurement count, properly associating corresponding species group.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/reshape_catch_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reshape Catch Data with Length Groupings — reshape_catch_data","text":"","code":"if (FALSE) { # \\dontrun{ # Reshape catch data from raw survey catch_long <- reshape_catch_data(raw_survey_data)  # Analyze counts by length range catch_long |>   dplyr::filter(!is.na(count)) |>   dplyr::group_by(species, length_range) |>   dplyr::summarize(total_count = sum(as.numeric(count), na.rm = TRUE))  # View fish over 100cm with their specific lengths catch_long |>   dplyr::filter(length_range == \"over100\") |>   dplyr::select(submission_id, species, length_over, count) } # }"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/reshape_species_groups.html","id":null,"dir":"Reference","previous_headings":"","what":"Reshape Species Groups from Wide to Long Format — reshape_species_groups","title":"Reshape Species Groups from Wide to Long Format — reshape_species_groups","text":"function converts data frame containing repeated species group columns (species_group.0, species_group.1, etc.) long format species group represented separate row, column indicating group belongs .","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/reshape_species_groups.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reshape Species Groups from Wide to Long Format — reshape_species_groups","text":"","code":"reshape_species_groups(df = NULL)"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/reshape_species_groups.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reshape Species Groups from Wide to Long Format — reshape_species_groups","text":"df data frame containing species group data wide format","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/reshape_species_groups.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reshape Species Groups from Wide to Long Format — reshape_species_groups","text":"data frame long format row representing single species group record","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/reshape_species_groups.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Reshape Species Groups from Wide to Long Format — reshape_species_groups","text":"function identifies columns follow pattern \"species_group.X\" restructures data species group submission represented separate row. removes position prefix column names adds n_catch column track group number (1-based indexing). Rows contain NA values filtered .","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/reshape_species_groups.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Reshape Species Groups from Wide to Long Format — reshape_species_groups","text":"","code":"if (FALSE) { # \\dontrun{ long_species_data <- reshape_species_groups(catch_info) } # }"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/summarize_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarize WorldFish Survey Data — summarize_data","title":"Summarize WorldFish Survey Data — summarize_data","text":"Processes validated survey data WorldFish sources, filtering flagged submissions generating summary datasets various dimensions: Monthly summaries aggregated catch metrics Taxa summaries species-specific information District summaries submission effort metrics Gear summaries gear-specific performance metrics Grid summaries vessel tracking data","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/summarize_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarize WorldFish Survey Data — summarize_data","text":"","code":"summarize_data(log_threshold = logger::DEBUG)"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/summarize_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarize WorldFish Survey Data — summarize_data","text":"log_threshold logging level threshold logger package (e.g., DEBUG, INFO) See logger::log_levels available options.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/summarize_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarize WorldFish Survey Data — summarize_data","text":"NULL (invisible). function uploads summary files cloud storage side effect.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/summarize_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Summarize WorldFish Survey Data — summarize_data","text":"function performs following operations: Retrieves validated WF survey data Filters approved validation status Creates multiple summary datasets: Monthly summaries: Average catch, price, CPUE, RPUE district month Taxa summaries: Catch metrics species, district, month District summaries: Submission counts effort metrics district Gear summaries: Performance metrics gear type Grid summaries: Downloaded cloud storage Uploads summaries cloud storage versioned parquet files metrics calculated include: Total mean catch weight Price per kg catch CPUE (Catch Per Unit Effort) - hourly daily RPUE (Revenue Per Unit Effort) - hourly daily Number submissions fishers Trip duration","code":""},{"path":[]},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/summarize_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarize WorldFish Survey Data — summarize_data","text":"","code":"if (FALSE) { # \\dontrun{ # Summarize WF data with default debug logging summarize_data()  # Summarize with info-level logging only summarize_data(logger::INFO) } # }"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/sync_device_users.html","id":null,"dir":"Reference","previous_headings":"","what":"Sync Device Users to MongoDB and Update Airtable — sync_device_users","title":"Sync Device Users to MongoDB and Update Airtable — sync_device_users","text":"Retrieves device data Airtable, joins user data, generates passwords new users, updates Airtable users table new passwords, pushes combined dataset MongoDB. function maintains user credentials devices Africa timezones complete synchronization systems.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/sync_device_users.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sync Device Users to MongoDB and Update Airtable — sync_device_users","text":"","code":"sync_device_users(pars = NULL, seed = 123)"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/sync_device_users.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sync Device Users to MongoDB and Update Airtable — sync_device_users","text":"pars List. Configuration parameters (defaults read_config()). Must contain airtable (token, frame tracks_app base_ids) storage (mongodb tracks_app connection_string, database_name, collection) configuration. seed Numeric. Random seed password generation (default: 123). Set NULL random passwords time.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/sync_device_users.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sync Device Users to MongoDB and Update Airtable — sync_device_users","text":"List containing user data counts, Airtable sync result, MongoDB push result. total_users: Number users synchronized MongoDB new_passwords_generated: Number new passwords created airtable_sync_result: Result syncing users Airtable (updates + creates) mongodb_result: Result MongoDB data push","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/sync_device_users.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Sync Device Users to MongoDB and Update Airtable — sync_device_users","text":"function performs following steps: Retrieves users data Airtable tracks_app base Retrieves device data Airtable frame base (pds_devices table) Filters devices Africa timezones Joins devices existing user data IMEI Generates 8-character alphanumeric passwords users without passwords Removes duplicate IMEI entries (keeps latest) Syncs complete user dataset Airtable users table (updates existing, creates new) Pushes complete dataset MongoDB Password generation uses letters (upper/lower), numbers (0-9), reproducible seed provided. function ensures complete synchronization updating Airtable MongoDB data.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/sync_device_users.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sync Device Users to MongoDB and Update Airtable — sync_device_users","text":"","code":"if (FALSE) { # \\dontrun{ # Using default configuration and seed result <- sync_device_users() cat(\"Generated\", result$new_passwords_generated, \"new passwords\") cat(\"Synced\", result$total_users, \"users to MongoDB\")  # Using custom configuration and random passwords custom_config <- read_config(\"custom_conf.yml\") result <- sync_device_users(custom_config, seed = NULL)  # Check Airtable sync results if (!is.null(result$airtable_sync_result)) {   cat(\"Successfully synced users to Airtable\")   cat(\"Updates:\", length(result$airtable_sync_result$updates))   cat(\"Creates:\", length(result$airtable_sync_result$creates)) } } # }"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/sync_validation_submissions.html","id":null,"dir":"Reference","previous_headings":"","what":"Synchronize Validation Statuses with KoboToolbox — sync_validation_submissions","title":"Synchronize Validation Statuses with KoboToolbox — sync_validation_submissions","text":"Synchronizes validation statuses local system KoboToolbox processing validation flags updating submission statuses accordingly. function follows Kenya pipeline pattern rate limiting, manual approval respect, optimized API usage.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/sync_validation_submissions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Synchronize Validation Statuses with KoboToolbox — sync_validation_submissions","text":"","code":"sync_validation_submissions(log_threshold = logger::DEBUG)"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/sync_validation_submissions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Synchronize Validation Statuses with KoboToolbox — sync_validation_submissions","text":"log_threshold logging level threshold logger package (e.g., DEBUG, INFO). Default logger::DEBUG.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/sync_validation_submissions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Synchronize Validation Statuses with KoboToolbox — sync_validation_submissions","text":"None. function performs status updates database operations side effects.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/sync_validation_submissions.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Synchronize Validation Statuses with KoboToolbox — sync_validation_submissions","text":"function follows steps: Downloads current validation flags cloud storage Sets parallel processing rate limiting Fetches current validation status KoboToolbox FIRST (updates) Identifies manually approved submissions (excluding system username) Updates flagged submissions \"approved\" (EXCLUDING manual approvals) Updates clean submissions \"approved\" (SKIPPING already-approved ones) Fetches final validation status updates Combines results pushes MongoDB record-keeping Key improvements previous implementation: Rate limiting prevents overwhelming KoboToolbox API Manual approvals respected never overwritten Already-approved submissions skipped minimize API calls Better error tracking logging","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/sync_validation_submissions.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Synchronize Validation Statuses with KoboToolbox — sync_validation_submissions","text":"function requires proper configuration config file, including: MongoDB connection parameters KoboToolbox asset ID token (configured ingestion$kobo-adnap) KoboToolbox username (identify system approvals) Google cloud storage parameters","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/sync_validation_submissions.html","id":"parallel-processing","dir":"Reference","previous_headings":"","what":"Parallel Processing","title":"Synchronize Validation Statuses with KoboToolbox — sync_validation_submissions","text":"function uses future furrr packages parallel processing, number workers set system cores minus 2 prevent resource exhaustion. Rate limiting implemented via Sys.sleep() respect API constraints.","code":""},{"path":[]},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/sync_validation_submissions.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Synchronize Validation Statuses with KoboToolbox — sync_validation_submissions","text":"","code":"if (FALSE) { # \\dontrun{ # Run with default DEBUG logging sync_validation_submissions()  # Run with INFO level logging sync_validation_submissions(log_threshold = logger::INFO) } # }"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/update_airtable_record.html","id":null,"dir":"Reference","previous_headings":"","what":"Update Single Airtable Record — update_airtable_record","title":"Update Single Airtable Record — update_airtable_record","text":"Updates specific fields one record.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/update_airtable_record.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update Single Airtable Record — update_airtable_record","text":"","code":"update_airtable_record(base_id, table_name, token, record_id, updates)"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/update_airtable_record.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update Single Airtable Record — update_airtable_record","text":"base_id Character string. Airtable base ID. table_name Character string. Name table. token Character string. Airtable API token. record_id Character string. ID record update. updates Named list. Fields values update.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/update_airtable_record.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Update Single Airtable Record — update_airtable_record","text":"httr2 response object.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/update_validation_status.html","id":null,"dir":"Reference","previous_headings":"","what":"Update Validation Status in KoboToolbox — update_validation_status","title":"Update Validation Status in KoboToolbox — update_validation_status","text":"Updates validation status specific submission KoboToolbox. function allows setting status approved, approved, hold.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/update_validation_status.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update Validation Status in KoboToolbox — update_validation_status","text":"","code":"update_validation_status(   submission_id = NULL,   asset_id = NULL,   token = NULL,   status = \"validation_status_approved\",   debug = FALSE )"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/update_validation_status.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update Validation Status in KoboToolbox — update_validation_status","text":"submission_id Character string. ID submission update. asset_id Character string. asset ID KoboToolbox. token Character string. authorization token KoboToolbox API. status Character string. validation status set. Must one : \"validation_status_approved\", \"validation_status_not_approved\", \"validation_status_on_hold\". debug Logical. TRUE, prints request object response. Default FALSE.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/update_validation_status.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Update Validation Status in KoboToolbox — update_validation_status","text":"tibble one row containing: submission_id ID updated submission validation_status new validation status validated_at Timestamp validation POSIXct validated_by Username validator update_success Logical indicating update successful","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/update_validation_status.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Update Validation Status in KoboToolbox — update_validation_status","text":"","code":"if (FALSE) { # \\dontrun{ # Update a single submission update_validation_status(   submission_id = \"1234567\",   asset_id = \"your asset id\",   token = \"Token YOUR_TOKEN_HERE\",   status = \"validation_status_approved\" )  # Update multiple submissions using purrr submission_ids <- c(\"1234567\", \"154267\") submission_ids %>%   purrr::map_dfr(update_validation_status,     asset_id = \"your asset id\",     token = \"Token YOUR_TOKEN_HERE\",     status = \"validation_status_approved\"   ) } # }"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/upload_cloud_file.html","id":null,"dir":"Reference","previous_headings":"","what":"Upload File to Cloud Storage — upload_cloud_file","title":"Upload File to Cloud Storage — upload_cloud_file","text":"function uploads one files cloud storage.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/upload_cloud_file.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Upload File to Cloud Storage — upload_cloud_file","text":"","code":"upload_cloud_file(file, provider, options, name = file)"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/upload_cloud_file.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Upload File to Cloud Storage — upload_cloud_file","text":"file character vector file paths upload. provider character string specifying cloud storage provider. options named list cloud storage provider options. name character vector names assign files cloud storage. Defaults local filenames.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/upload_cloud_file.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Upload File to Cloud Storage — upload_cloud_file","text":"list upload metadata.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/upload_cloud_file.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Upload File to Cloud Storage — upload_cloud_file","text":"","code":"if (FALSE) { # \\dontrun{ upload_cloud_file(   file = \"data.parquet\",   provider = \"gcs\",   options = list(bucket = \"my-bucket\"),   name = \"data/processed.parquet\" ) } # }"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/upload_parquet_to_cloud.html","id":null,"dir":"Reference","previous_headings":"","what":"Upload Data as Parquet File to Cloud Storage — upload_parquet_to_cloud","title":"Upload Data as Parquet File to Cloud Storage — upload_parquet_to_cloud","text":"function uploads data frame Parquet file cloud storage versioning support.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/upload_parquet_to_cloud.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Upload Data as Parquet File to Cloud Storage — upload_parquet_to_cloud","text":"","code":"upload_parquet_to_cloud(   data,   prefix,   provider,   options,   compression = \"lz4\",   compression_level = 12 )"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/upload_parquet_to_cloud.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Upload Data as Parquet File to Cloud Storage — upload_parquet_to_cloud","text":"data data frame containing data uploaded. prefix character string specifying file prefix path. provider character string specifying cloud storage provider key. options named list cloud storage provider options. compression character string specifying compression type. Default \"lz4\". compression_level integer specifying compression level. Default 12.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/upload_parquet_to_cloud.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Upload Data as Parquet File to Cloud Storage — upload_parquet_to_cloud","text":"NULL (called side effects)","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/upload_parquet_to_cloud.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Upload Data as Parquet File to Cloud Storage — upload_parquet_to_cloud","text":"","code":"if (FALSE) { # \\dontrun{ # Upload survey data upload_parquet_to_cloud(   data = survey_data,   prefix = \"raw-data/survey-data\",   provider = conf$storage$google$key,   options = conf$storage$google$options ) } # }"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/validate_catch_taxa.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate Catch at Taxon Level — validate_catch_taxa","title":"Validate Catch at Taxon Level — validate_catch_taxa","text":"Flags outliers catch_kg comparing values upper bounds computed per gear + catch_taxon group (via get_catch_bounds_taxon). Rows catch_kg bound receive numeric alert code optionally catch_kg set NA.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/validate_catch_taxa.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate Catch at Taxon Level — validate_catch_taxa","text":"","code":"validate_catch_taxa(data, k = 3, flag_value = 4)"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/validate_catch_taxa.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validate Catch at Taxon Level — validate_catch_taxa","text":"data data frame containing (least) submission_id, gear, catch_taxon, catch_kg. k numeric parameter passed LocScaleB; used computing outlier bounds get_catch_bounds_taxon. flag_value numeric value assign catch_kg exceeds upper bound. Default 4.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/validate_catch_taxa.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Validate Catch at Taxon Level — validate_catch_taxa","text":"data frame columns: submission_id Carried input data. catch_taxon Carried input data. catch_kg Potentially modified outlier. alert_catch alert code flag_value outliers, NA_real_ outlier.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/validate_catch_taxa.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Validate Catch at Taxon Level — validate_catch_taxa","text":"Calls get_catch_bounds_taxon retrieve outlier bounds gear + catch_taxon group. Joins bounds data gear catch_taxon. Rowwise, checks catch_kg greater bound upper.. , sets alert_catch = flag_value optionally replaces catch_kg NA_real_.","code":""},{"path":[]},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/validate_catch_taxa.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Validate Catch at Taxon Level — validate_catch_taxa","text":"","code":"if (FALSE) { # \\dontrun{ catch_alert <- validate_catch_taxa(data, k = 3, flag_value = 4) head(catch_alert) } # }"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/validate_price.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate Catch Price — validate_price","title":"Validate Catch Price — validate_price","text":"Detects outliers catch_price gear + catch_taxon, assigning numeric alert code records exceeding computed upper bound. Outliers can replaced NA.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/validate_price.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate Catch Price — validate_price","text":"","code":"validate_price(data, k = 3, flag_value = 6)"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/validate_price.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validate Catch Price — validate_price","text":"data data frame submission_id, gear, catch_taxon, catch_price. k numeric parameter passed LocScaleB, used get_price_bounds. flag_value numeric code (default 6) assigned outlier prices.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/validate_price.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Validate Catch Price — validate_price","text":"data frame columns: submission_id Carried input. catch_taxon Carried input. catch_price Potentially set NA outlier. alert_price numeric alert code, NA.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/validate_price.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Validate Catch Price — validate_price","text":"Calls get_price_bounds compute outlier thresholds. Joins thresholds back data via gear catch_taxon. Rowwise, flags prices upper.bound alert_price, replaces NA_real_.","code":""},{"path":[]},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/validate_price.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Validate Catch Price — validate_price","text":"","code":"if (FALSE) { # \\dontrun{ price_alert <- validate_price(data, k = 3, flag_value = 6) head(price_alert) } # }"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/validate_surveys_adnap.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate ADNAP Survey Data — validate_surveys_adnap","title":"Validate ADNAP Survey Data — validate_surveys_adnap","text":"Validates ADNAP survey data applying quality control checks integrating KoBoToolbox validation status. function filters submissions meet validation criteria processes catch data. Approved submissions KoBoToolbox bypass automatic validation flags.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/validate_surveys_adnap.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate ADNAP Survey Data — validate_surveys_adnap","text":"","code":"validate_surveys_adnap(log_threshold = logger::DEBUG)"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/validate_surveys_adnap.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validate ADNAP Survey Data — validate_surveys_adnap","text":"log_threshold logging level threshold logger package (e.g., DEBUG, INFO)","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/validate_surveys_adnap.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Validate ADNAP Survey Data — validate_surveys_adnap","text":"Invisible NULL. function uploads two datasets Google Cloud Storage: Validation flags submission Validated survey data invalid submissions removed","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/validate_surveys_adnap.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Validate ADNAP Survey Data — validate_surveys_adnap","text":"validation process follows two-stage approach: Stage 1: Basic Data Quality Checks (Flags 1-7) Form completeness: Catch outcome \"1\" catch_taxon missing Catch info completeness: Catch taxon exists weight individuals Length validation: Fish length species minimum Length validation: Fish length species 75th percentile maximum Bucket weight: Weight per bucket exceeds 50kg Bucket count: Number buckets exceeds 300 Individual count: Number individuals exceeds 200 per record Stage 2: Composite Economic Indicators (Flags 8-10) Price per kg: Exceeds 2500 MZN/kg (~30 EUR/kg) CPUE: Catch per unit effort exceeds 30 kg/fisher/hour RPUE: Revenue per unit effort exceeds 2500 MZN/fisher/hour KoBoToolbox Integration: function queries KoBoToolbox validation status submission. Submissions marked \"validation_status_approved\" KoBoToolbox flags cleared included validated dataset regardless automatic checks.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/validate_surveys_adnap.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Validate ADNAP Survey Data — validate_surveys_adnap","text":"Requires configuration parameters config.yml KoBoToolbox credentials Downloads preprocessed survey data Google Cloud Storage Uses parallel processing query KoBoToolbox validation status Submissions approved KoBoToolbox bypass automatic validation flags Sets catch_kg 0 catch_outcome 0","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/validate_surveys_adnap.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Validate ADNAP Survey Data — validate_surveys_adnap","text":"","code":"if (FALSE) { # \\dontrun{ validate_surveys_adnap() } # }"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/validate_surveys_lurio.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate Lurio Survey Data — validate_surveys_lurio","title":"Validate Lurio Survey Data — validate_surveys_lurio","text":"function validates preprocessed fisheries survey data using comprehensive approach adapted Peskas Zanzibar pipeline. performs basic data quality checks composite economic indicator validation ensure data integrity.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/validate_surveys_lurio.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate Lurio Survey Data — validate_surveys_lurio","text":"","code":"validate_surveys_lurio(log_threshold = logger::DEBUG)"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/validate_surveys_lurio.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validate Lurio Survey Data — validate_surveys_lurio","text":"log_threshold Logging threshold level (default: logger::DEBUG)","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/validate_surveys_lurio.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Validate Lurio Survey Data — validate_surveys_lurio","text":"function return value. Instead, processes data uploads validated results validation flags cloud storage.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/validate_surveys_lurio.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Validate Lurio Survey Data — validate_surveys_lurio","text":"validation process follows two-stage approach: Stage 1: Basic Data Quality Checks (Flags 1-7) Form completeness: Catch outcome \"1\" catch_taxon missing Catch info completeness: Catch taxon exists weight individuals Length validation: Fish length species minimum Length validation: Fish length species 75th percentile maximum Bucket weight: Weight per bucket exceeds 50kg Bucket count: Number buckets exceeds 300 Individual count: Number individuals exceeds 200 per record Stage 2: Composite Economic Indicators (Flags 8-10) Price per kg: Exceeds 1875 MZN/kg (~30 EUR/kg, following Zanzibar thresholds) CPUE: Catch per unit effort exceeds 30 kg/fisher/day RPUE: Revenue per unit effort exceeds 1875 MZN/fisher/day Submissions validation flags excluded final validated dataset flags preserved data quality monitoring.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/validate_surveys_lurio.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Validate Lurio Survey Data — validate_surveys_lurio","text":"function requires configuration file accessible via read_config() providing cloud storage connection details.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/validate_surveys_lurio.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Validate Lurio Survey Data — validate_surveys_lurio","text":"","code":"if (FALSE) { # \\dontrun{ validate_surveys_lurio() } # }"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/validate_total_catch.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate Total Catch — validate_total_catch","title":"Validate Total Catch — validate_total_catch","text":"Aggregates catch_kg total per submission_id, landing_site, gear, computes outlier bounds landing site + gear, flags outlier total catches. Outliers assigned numeric flag_value optionally set NA.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/validate_total_catch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate Total Catch — validate_total_catch","text":"","code":"validate_total_catch(data, k = 3, flag_value = 5)"},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/validate_total_catch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validate Total Catch — validate_total_catch","text":"data data frame containing submission_id, landing_site, gear, catch_kg. k numeric parameter passed LocScaleB, used bounding outliers get_total_catch_bounds. flag_value numeric value assign records whose total catch upper bound. Default 5.","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/validate_total_catch.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Validate Total Catch — validate_total_catch","text":"data frame columns: submission_id total_catch_kg (potentially set NA outlier) alert_total (alert code NA_real_)","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/validate_total_catch.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Validate Total Catch — validate_total_catch","text":"Groups data submission_id, landing_site, gear sums catch_kg total_catch_kg. Retrieves outlier bounds get_total_catch_bounds. Flags total_catch_kg upper.alert_total. Sets outlier values NA_real_.","code":""},{"path":[]},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/reference/validate_total_catch.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Validate Total Catch — validate_total_catch","text":"","code":"if (FALSE) { # \\dontrun{ total_catch_alert <- validate_total_catch(data, k = 3, flag_value = 5) head(total_catch_alert) } # }"},{"path":[]},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/news/index.html","id":"major-changes-2-1-0","dir":"Changelog","previous_headings":"","what":"Major Changes","title":"peskas.mozambique.data.pipeline 2.1.0","text":"Added sync_validation_submissions() bidirectional validation status updates rate limiting Implemented process_submissions_parallel() helper function consistent API interactions Rate limiting (0.1-0.2s delays) prevents overwhelming KoboToolbox API Manual approval respect: Human review decisions never overwritten system updates Optimized API usage: Skips already-approved submissions minimize unnecessary calls Fetches current validation status making updates smarter decision-making Automated approval/rejection submissions KoboToolbox based validation results Stores validation metadata MongoDB enumerator performance tracking Enhanced error tracking success/failure logging Preprocessing functions now automatically filter Airtable assets form_id Better separation metadata Lurio ADNAP survey forms Improved handling shared assets across multiple survey versions reliable species, gear, vessel, site mappings Combined ingest preprocess jobs data source (Lurio, ADNAP, PDS) reducing container startups ~30% Simplified dependency graph 10 jobs 7 jobs faster pipeline execution Maintained separation validation stages better error isolation independent re-runs Aligned workflow structure Kenya pipeline best practices","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/news/index.html","id":"improvements-2-1-0","dir":"Changelog","previous_headings":"","what":"Improvements","title":"peskas.mozambique.data.pipeline 2.1.0","text":"Manual approvals human reviewers now properly bypass automatic validation flags System-generated approvals re-validated ensure data quality Better logging validation status queries submission counts Enhanced validation flag preservation monitoring reporting Improved handling catch_taxon field mapping Lurio surveys Restructured MongoDB connection strings support separate validation database Added KOBO_TOKEN authentication ADNAP asset Improved configuration structure multiple database contexts Enhanced PDS storage configuration organization Added explicit assets configuration Airtable integration Reduced overall pipeline execution time job consolidation Parallel execution independent data streams (Lurio, ADNAP, PDS) Cleaner job naming better CI/CD monitoring Maintained robust error handling granular validation stages Added new exported functions: summarize_data(), sync_validation_submissions(), process_submissions_parallel() Enhanced function documentation proper importFrom declarations Improved variable scoping data pipeline clarity Better separation concerns preprocessing validation Centralized API interaction logic reusable helper functions","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/news/index.html","id":"bug-fixes-2-1-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"peskas.mozambique.data.pipeline 2.1.0","text":"Fixed asset fetching logic properly filter target form_id Corrected catch_taxon column mapping Lurio validation (changed alpha3_code) Fixed validation status query exclude system approvals manual approval overrides Fixed MongoDB configuration path typo (collection → collections) enumerators_stats Removed redundant asset fetching code preprocessing functions Added missing KOBO_USERNAME configuration ADNAP asset Fixed sync function never overwrite manual approvals human reviewers","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/news/index.html","id":"infrastructure--dependencies-2-1-0","dir":"Changelog","previous_headings":"","what":"Infrastructure & Dependencies","title":"peskas.mozambique.data.pipeline 2.1.0","text":"Added MONGODB_CONNECTION_STRING_VALIDATION environment variable separate validation database Enhanced GitHub Actions workflow combined ingest-preprocess jobs Improved parallel processing configuration validation sync Updated NAMESPACE new imports future, furrr, progressr packages Maintained compatibility existing storage authentication systems","code":""},{"path":[]},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/news/index.html","id":"major-changes-2-0-0","dir":"Changelog","previous_headings":"","what":"Major Changes","title":"peskas.mozambique.data.pipeline 2.0.0","text":"Added ingest_landings_lurio() ingest_landings_adnap() separate survey data streams Implemented preprocess_landings_lurio() preprocess_landings_adnap() survey-specific transformations Created validate_surveys_lurio() validate_surveys_adnap() tailored validation rules Added calculate_catch_lurio() calculate_catch_adnap() survey-specific catch weight estimation Introduced survey version detection adaptive processing via reshape_catch_data() Integrated KoBoToolbox validation status API manual approval workflow Added get_validation_status() query submission approval status Implemented parallel processing validation status queries across multiple submissions Manual approvals KoBoToolbox now bypass automatic validation flags Maintained two-stage validation (7 basic checks + 3 composite economic indicators) Introduced reshape_species_groups() converting wide-format species data long format Created reshape_catch_data() supporting version 1 version 2 survey structures Added preprocess_catch() automatic survey version detection Implemented preprocess_general_adnap() ADNAP-specific trip information processing Enhanced handling nested length groups fish 100cm Renamed workflow jobs better visibility (e.g., “Ingest Lurio landings”, “Validate ADNAP landings”) Parallel execution Lurio ADNAP pipelines faster processing Separate PDS data ingestion preprocessing jobs Clear dependency chains ingestion, preprocessing, validation stages","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/news/index.html","id":"improvements-2-0-0","dir":"Changelog","previous_headings":"","what":"Improvements","title":"peskas.mozambique.data.pipeline 2.0.0","text":"Corrected storage backend references MongoDB Google Cloud Storage Updated function documentation accurately reflect Parquet file usage Added specific titles distinguish Lurio ADNAP functions Removed misleading unused parameters ingestion functions Added explicit invisible(NULL) returns workflow functions consistency Enhanced documentation KoBoToolbox validation integration Improved parameter documentation honesty (noting hardcoded values) Cleaned function signatures removing unused parameters Made return values explicit across workflow functions Improved consistency function documentation implementation Enhanced examples reflect actual usage patterns Added support multiple species field normalization Improved handling separate length group structures large fish Enhanced catch data validation species-specific thresholds Better integration Airtable form assets data mapping","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/news/index.html","id":"bug-fixes-2-0-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"peskas.mozambique.data.pipeline 2.0.0","text":"Fixed incorrect package reference documentation (removed non-existent KoboconnectR package) Corrected validation threshold documentation (200 individuals, 100) ADNAP surveys Fixed duplicate GitHub Actions job names made debugging difficult Corrected storage backend documentation throughout codebase (MongoDB → GCS) Updated validation flag numbering documentation consistency across surveys","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/news/index.html","id":"infrastructure--dependencies-2-0-0","dir":"Changelog","previous_headings":"","what":"Infrastructure & Dependencies","title":"peskas.mozambique.data.pipeline 2.0.0","text":"Maintained compatibility parallel processing packages (future, furrr) Enhanced configuration system support multiple survey sources Improved separation concerns Lurio ADNAP processing pipelines Updated documentation generation roxygen2 Package maintains clean R CMD check status","code":""},{"path":[]},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/news/index.html","id":"major-changes-1-0-0","dir":"Changelog","previous_headings":"","what":"Major Changes","title":"peskas.mozambique.data.pipeline 1.0.0","text":"Added ingest_pds_trips() retrieve store GPS trip metadata PDS API Added ingest_pds_tracks() download individual trip point data parallel processing support Implemented get_trips() get_trip_points() functions PDS API interaction Added preprocess_pds_tracks() track data cleaning feature extraction Introduced preprocess_track_data() configurable track processing pipelines Created generate_track_summaries() trip-level metrics calculation Implemented airtable_to_df() automatic pagination full table retrieval Added device_sync() intelligent device data synchronization (updates existing, creates new) Created sync_device_users() manage vessel user credentials across Airtable MongoDB Developed bulk_update_airtable() df_to_airtable() batch operations Added get_writable_fields() identify editable fields prevent computed field errors Redesigned validate_landings() 10 validation flags across two stages Stage 1: Basic data quality checks (form completeness, catch info, length validation, bucket/individual counts) Stage 2: Composite economic indicators (price per kg, CPUE, RPUE) following Zanzibar thresholds Created modular validation functions: validate_catch_taxa(), validate_price(), validate_total_catch() Validation results exclude flagged submissions final dataset preserving flags monitoring Introduced match_species_from_taxa() using fuzzy matching FishBase SeaLifeBase Implemented get_fao_groups() commercial species categorization Added get_species_areas_batch() biogeographic validation Created get_length_weight_batch() length-weight relationship parameters Developed getLWCoeffs() retrieve stored coefficients local database Added process_species_list() batch processing automatic fallback logic","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/news/index.html","id":"improvements-1-0-0","dir":"Changelog","previous_headings":"","what":"Improvements","title":"peskas.mozambique.data.pipeline 1.0.0","text":"Migrated primary storage Google Cloud Storage Parquet format Added upload_parquet_to_cloud() download_parquet_from_cloud() versioning support Implemented cloud_storage_authenticate() temporary credential file handling Created cloud_object_name() version-aware object retrieval MongoDB maintained secondary storage legacy compatibility Moved length-weight coefficients data/ inst/ directory better package structure Switched dotenv package environment variable management Added load_dotenv() function configurable .env file paths Updated read_config() automatically load environment variables Expanded configuration schema support PDS, Airtable, multi-cloud storage Added support separate storage buckets different data types (surveys vs. tracks) Enhanced preprocess_landings() metadata table joins (landing sites, boats, enumerators) Implemented process_species_group() handling species group disaggregation Added species validation enrichment FishBase/SeaLifeBase data Integrated length-weight conversion using local coefficient database Added habitat information species area data Improved catch weight calculation multiple estimation methods Expanded export_landings() generate multiple analytical outputs Added calculate_fishery_metrics() aggregated statistics Created MongoDB portal collections dashboard integration Implemented trip-level summarization GPS track data Enhanced data transformation consumption visualization tools Added GitHub Actions workflow automated releases (release.yaml) Updated data pipeline workflow improved error handling notifications Integrated cloud authentication CI/CD pipeline Added support scheduled manual workflow triggers","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/news/index.html","id":"bug-fixes-1-0-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"peskas.mozambique.data.pipeline 1.0.0","text":"Fixed price validation logic incorrectly flagging valid entries (#PR/issue reference applicable) Corrected global variable bindings validation functions prevent R CMD check warnings Removed invalid geo parameter mdb_collection_push() function call Fixed customer_name submission_id variable scoping issues using .data$ notation","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/news/index.html","id":"infrastructure--dependencies-1-0-0","dir":"Changelog","previous_headings":"","what":"Infrastructure & Dependencies","title":"peskas.mozambique.data.pipeline 1.0.0","text":"Added new package dependencies: furrr, future, glue, readr enhanced functionality Updated .Rbuildignore exclude development files (.env, .claude, CLAUDE.md) Package now passes R CMD check warnings notes Improved documentation coverage 34 new exported functions Enhanced type safety code consistency throughout codebase","code":""},{"path":[]},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/news/index.html","id":"new-features-0-2-0","dir":"Changelog","previous_headings":"","what":"New features","title":"peskas.mozambique.data.pipeline 0.2.0","text":"Updates data ingestion preprocessing workflows Renames ingest_surveys ingest_landings Adds new metadata joins data transformations preprocess_landings Introduces calculate_catch function catch weight estimation Updates configuration include Google Cloud Storage additional metadata tables","code":""},{"path":"https://worldfishcenter.github.io/peskas.malawi.data.pipeline/news/index.html","id":"peskasmozambiquedatapipeline-010","dir":"Changelog","previous_headings":"","what":"peskas.mozambique.data.pipeline 0.1.0","title":"peskas.mozambique.data.pipeline 0.1.0","text":"Initial CRAN submission.","code":""}]
